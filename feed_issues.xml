<?xml version='1.0' encoding='UTF-8'?>
<rss version="2.0">
  <channel>
    <title>GitHub issues Feed</title>
    <link>https://github.com/username/repo/issues</link>
    <description>Recent issues from GitHub repo</description>
    <item>
      <title>[inductor][cpp] expose config options via env vars</title>
      <link>https://github.com/pytorch/pytorch/pull/123519</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #123519</p>
<p>cc @voznesenskym @penguinwu @EikanWang @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Sat, 06 Apr 2024 23:13:19 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/123519</guid>
    </item>
    <item>
      <title>[inductor] Freeze the layout of the conv input to channels_last</title>
      <link>https://github.com/pytorch/pytorch/pull/122765</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122765</p>
<p>Fix https://github.com/pytorch/pytorch/issues/118082.</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 26 Mar 2024 21:27:54 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122765</guid>
    </item>
    <item>
      <title>[inductor] modify the output_stride of ConcatKernel</title>
      <link>https://github.com/pytorch/pytorch/pull/122761</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122761</p>
<p>Fix https://github.com/pytorch/pytorch/issues/121613.<br />
Modify the <code>output_stride</code> of <code>ConcatKernel</code>: If any input to <code>Concat</code> is <code>Pointwise</code>, check the layout of all inputs to <code>Pointwise</code>, if any of the inputs is in channels_last format, set channels_last strides for the <code>output_stride</code>.</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 26 Mar 2024 19:57:00 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122761</guid>
    </item>
    <item>
      <title>[inductor] Modify the rules for freezing the layout of x.unwrap_view() in convert_to_reinterpret_view</title>
      <link>https://github.com/pytorch/pytorch/pull/122760</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122760</p>
<p>Fix https://github.com/pytorch/pytorch/issues/121607</p>
<p>Modify the rules for freezing the layout of <code>x.unwrap_view()</code> in <code>convert_to_reinterpret_view</code>: If any read of <code>x.unwrap_view()</code> is in channels_last format, freeze the layout of <code>x.unwrap_view()</code> to channels_last format. </p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 26 Mar 2024 19:30:26 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122760</guid>
    </item>
    <item>
      <title>Add registration API for torch.compile-eager</title>
      <link>https://github.com/pytorch/pytorch/pull/121387</link>
      <description><![CDATA[<p>This PR is a follow-up of RFC https://github.com/pytorch/pytorch/issues/115545.</p>
<p>In this PR, we intend to provide a registration API dedicated to eager-through-torch.compile. The major workflow of this API will be as follows.</p>
<ul>
<li>Load cache</li>
<li>Check cache according to the input tensors</li>
<li>Cache Hit: Run the cached kernel directly</li>
<li>Cache Miss: Run the registered python kernel</li>
</ul>
<p>Currently, this PR always fallback to python kernel now and cache mechanism will be implemented in another PR.</p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #120595<br />
* #116449<br />
* #116368<br />
* #121727<br />
* <strong>-&gt;</strong> #121387<br />
* #121296</p>
<p>cc @voznesenskym @penguinwu @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Wed, 06 Mar 2024 22:35:58 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/121387</guid>
    </item>
    <item>
      <title>Torch compile does not work on python 3.12</title>
      <link>https://github.com/pytorch/pytorch/issues/120233</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>Currently torch, as of 2.2.0 does not support torch compile with python 3.12</p>
<p>See following PR for example: https://github.com/pytorch/pytorch/pull/117853</p>
<ol>
<li>We need to be able to use python 3.12 with torch.compile feature. </li>
<li>Include triton with Linux 3.12 wheel </li>
<li>Enable Python 3.12 and torch.compile CI testsing</li>
</ol>
<p>cc: @albanD @malfet </p>
<h3>Versions</h3>
<p>2.2.0</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang</p>]]></description>
      <pubDate>Tue, 20 Feb 2024 06:14:41 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/120233</guid>
    </item>
    <item>
      <title>Back out "[pytorch][PR] [Inductor] GEMM shape padding improvements"</title>
      <link>https://github.com/pytorch/pytorch/pull/119325</link>
      <description><![CDATA[<p>Summary:<br />
Original commit changeset: f89e75856523</p>
<p>Original Phabricator Diff: D53227828</p>
<p>S393407</p>
<p>Test Plan:<br />
local light: light_cli:5049854</p>
<p>buck2 run mode/opt //minimal_viable_ai/models/blue_reels_vdd/tests:cogwheel_blue_reels_vdd_trunk_metrics_test-launcher --   --with-fbpkg light_cli:5049854 --with-fbpkg mvai_blue_reels_vdd:latest_contbuild --run-disabled --run-harness-in-tupperware</p>
<p>Differential Revision: D53492220</p>
<p>@diff-train-skip-merge</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 06 Feb 2024 14:36:14 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/119325</guid>
    </item>
  </channel>
</rss>
