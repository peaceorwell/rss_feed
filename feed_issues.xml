<?xml version='1.0' encoding='UTF-8'?>
<rss version="2.0">
  <channel>
    <title>GitHub issues Feed</title>
    <link>https://github.com/username/repo/issues</link>
    <description>Recent issues from GitHub repo</description>
    <item>
      <title>`torch.compile` fails with `jacfwd` when multiplying/dividing float and tensor</title>
      <link>https://github.com/pytorch/pytorch/issues/125078</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>The following minimal example fails<br />
```python<br />
import torch<br />
from torch.func import jacfwd</p>
<p>def func(x):<br />
    two = 2.0<br />
    return two * x</p>
<p>def jac_func(x):<br />
    return jacfwd(func, argnums=(0,))(x)</p>
<p>compiled_jac_func = torch.compile(jac_func)<br />
compiled_jac_func(torch.ones((3,), dtype=torch.float64))<br />
<code>with following last few lines in the error message (longer error log below).</code><br />
torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in function mul>(<em>(2.0, GradTrackingTensor(lvl=2, value=<br />
    FakeTensor(..., size=(3,), dtype=torch.float64)<br />
)), </em>*{}):<br />
aten::alias() Expected a value of type 'Tensor' for argument 'self' but instead found type 'float'.<br />
Position: 0<br />
Value: 2.0<br />
Declaration: aten::alias(Tensor(a) self) -&gt; Tensor(a)<br />
Cast error details: Unable to cast 2.0 to Tensor</p>
<p>from user code:<br />
   File "/home/cwtan/florch/tests/test.py", line 10, in jac_func<br />
    return jacfwd(func, argnums=(0,))(x)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py", line 1312, in wrapper_fn<br />
    results = vmap(push_jvp, randomness=randomness)(basis)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/apis.py", line 200, in wrapped<br />
    return vmap_impl(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 331, in vmap_impl<br />
    return _flat_vmap(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 48, in fn<br />
    return f(<em>args, </em><em>kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 480, in _flat_vmap<br />
    batched_outputs = func(</em>batched_inputs, <strong>kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py", line 1301, in push_jvp<br />
    output = _jvp_with_argnums(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 48, in fn<br />
    return f(*args, </strong>kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py", line 1141, in _jvp_with_argnums<br />
    result_duals = func(*duals)<br />
  File "/home/cwtan/florch/tests/test.py", line 6, in func<br />
    return two * x</p>
<p>Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information</p>
<p>You can suppress this exception and fall back to eager by setting:<br />
    import torch._dynamo<br />
    torch._dynamo.config.suppress_errors = True<br />
<code>Similar error if it's `return x / two`. Trying instead</code><br />
import torch<br />
from torch.func import jacfwd</p>
<p>def func(x):<br />
    two = torch.tensor([2.0], dtype=x.dtype, device=x.device)<br />
    return two * x</p>
<p>def jac_func(x):<br />
    return jacfwd(func, argnums=(0,))(x)</p>
<p>compiled_jac_func = torch.compile(jac_func)<br />
compiled_jac_func(torch.ones((3,), dtype=torch.float64))<br />
<code>also fails with a different `NotImplementedError` (full error below).</code><br />
torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:<br />
NotImplementedError: Cannot access storage of TensorWrapper<br />
```</p>
<h3>Error logs</h3>
<p>For the first example where <code>two = 2.0</code>.<br />
```<br />
refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> quantize_per_tensor<br />
refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> quantize_per_tensor<br />
refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> dequantize_per_tensor<br />
refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> dequantize_per_tensor<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] failed while attempting to run meta for aten.alias.default<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] Traceback (most recent call last):<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0]   File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py", line 1493, in _dispatch_impl<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0]     r = func(<em>args, </em><em>kwargs)<br />
E0426 18:03:00.287000 140386476729408 torch/<em>subclasses/fake_tensor.py:1497] [0/0]         ^^^^^^^^^^^^^^^^^^^^^<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0]   File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_ops.py", line 630, in <strong>call</strong><br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0]     return self</em>._op(</em>args, <strong>kwargs)<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0]            ^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] RuntimeError: aten::alias() Expected a value of type 'Tensor' for argument 'self' but instead found type 'float'.<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] Position: 0<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] Value: 2.0<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] Declaration: aten::alias(Tensor(a) self) -&gt; Tensor(a)<br />
E0426 18:03:00.287000 140386476729408 torch/_subclasses/fake_tensor.py:1497] [0/0] Cast error details: Unable to cast 2.0 to Tensor<br />
Traceback (most recent call last):<br />
  File "/home/cwtan/florch/tests/test.py", line 14, in <module><br />
    compiled_jac_func(torch.ones((3,), dtype=torch.float64))<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 403, in _fn<br />
    return fn(*args, </strong>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 977, in catch_errors<br />
    return callback(frame, cache_entry, hooks, frame_state, skip=1)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 818, in _convert_frame<br />
    result = inner_convert(<br />
             ^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 411, in _convert_frame_assert<br />
    return _compile(<br />
           ^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_utils_internal.py", line 70, in wrapper_function<br />
    return function(<em>args, </em><em>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/contextlib.py", line 81, in inner<br />
    return func(</em>args, <strong>kwds)<br />
           ^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 700, in _compile<br />
    guarded_code = compile_inner(code, one_graph, hooks, transform)<br />
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 268, in time_wrapper<br />
    r = func(*args, </strong>kwargs)<br />
        ^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 568, in compile_inner<br />
    out_code = transform_code_object(code, transform)<br />
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py", line 1116, in transform_code_object<br />
    transformations(instructions, code_options)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 173, in _fn<br />
    return fn(<em>args, </em><em>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 515, in transform<br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2237, in run<br />
    super().run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1848, in CALL<br />
    self.call_function(fn, args, kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1848, in CALL<br />
    self.call_function(fn, args, kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1301, in CALL_FUNCTION_EX<br />
    self.call_function(fn, argsvars.items, kwargsvars)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/higher_order_ops.py", line 1202, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 293, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1301, in CALL_FUNCTION_EX<br />
    self.call_function(fn, argsvars.items, kwargsvars)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 293, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1301, in CALL_FUNCTION_EX<br />
    self.call_function(fn, argsvars.items, kwargsvars)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 293, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1301, in CALL_FUNCTION_EX<br />
    self.call_function(fn, argsvars.items, kwargsvars)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1848, in CALL<br />
    self.call_function(fn, args, kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 293, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1301, in CALL_FUNCTION_EX<br />
    self.call_function(fn, argsvars.items, kwargsvars)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 293, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 492, in wrapper<br />
    return inner_fn(self, inst)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1301, in CALL_FUNCTION_EX<br />
    self.call_function(fn, argsvars.items, kwargsvars)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 730, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 293, in call_function<br />
    return super().call_function(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py", line 90, in call_function<br />
    return tx.inline_user_function_return(self, [</em>self.self_args(), <em>args], kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 736, in inline_user_function_return<br />
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2418, in inline_call<br />
    return cls.inline_call</em>(parent, func, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>dynamo/symbolic_convert.py", line 2534, in inline_call</em><br />
    tracer.run()<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run<br />
    while self.step():<br />
          ^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step<br />
    self.dispatch_table<a href="self, inst">inst.opcode</a><br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 1812, in BINARY_OP<br />
    return _binary_op_lookup<a href="self, inst">inst.arg</a><br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 229, in impl<br />
    self.push(fn_var.call_function(self, self.popn(nargs), {}))<br />
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 946, in call_function<br />
    return handler(tx, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 925, in _handle_insert_op_in_graph<br />
    return wrap_fx_proxy(tx, proxy)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/builder.py", line 1434, in wrap_fx_proxy<br />
    return wrap_fx_proxy_cls(target_cls=TensorVariable, </em><em>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/variables/builder.py", line 1519, in wrap_fx_proxy_cls<br />
    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)<br />
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 1821, in get_fake_value<br />
    raise TorchRuntimeError(str(e)).with_traceback(e.<strong>traceback</strong>) from None<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 1753, in get_fake_value<br />
    ret_val = wrap_fake_exception(<br />
              ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 1268, in wrap_fake_exception<br />
    return fn()<br />
           ^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 1754, in <lambda><br />
    lambda: run_node(tx.output, node, args, kwargs, nnmodule)<br />
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 1889, in run_node<br />
    raise RuntimeError(make_error_message(e)).with_traceback(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 1871, in run_node<br />
    return node.target(</em>args, <strong>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/utils/_stats.py", line 20, in wrapper<br />
    return fn(*args, </strong>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py", line 904, in <strong>torch_dispatch</strong><br />
    return self.dispatch(func, types, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py", line 1262, in dispatch<br />
    return self._cached_dispatch_impl(func, types, args, kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py", line 987, in _cached_dispatch_impl<br />
    output = self._dispatch_impl(func, types, args, kwargs)<br />
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py", line 1493, in _dispatch_impl<br />
    r = func(<em>args, </em><em>kwargs)<br />
        ^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/<em>ops.py", line 630, in <strong>call</strong><br />
    return self</em>._op(</em>args, <strong>kwargs)<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in function mul>(*(2.0, GradTrackingTensor(lvl=2, value=<br />
    FakeTensor(..., size=(3,), dtype=torch.float64)<br />
)), </strong>{}):<br />
aten::alias() Expected a value of type 'Tensor' for argument 'self' but instead found type 'float'.<br />
Position: 0<br />
Value: 2.0<br />
Declaration: aten::alias(Tensor(a) self) -&gt; Tensor(a)<br />
Cast error details: Unable to cast 2.0 to Tensor</p>
<p>from user code:<br />
   File "/home/cwtan/florch/tests/test.py", line 10, in jac_func<br />
    return jacfwd(func, argnums=(0,))(x)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py", line 1312, in wrapper_fn<br />
    results = vmap(push_jvp, randomness=randomness)(basis)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/apis.py", line 200, in wrapped<br />
    return vmap_impl(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 331, in vmap_impl<br />
    return _flat_vmap(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 48, in fn<br />
    return f(<em>args, </em><em>kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 480, in _flat_vmap<br />
    batched_outputs = func(</em>batched_inputs, <strong>kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py", line 1301, in push_jvp<br />
    output = _jvp_with_argnums(<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/vmap.py", line 48, in fn<br />
    return f(*args, </strong>kwargs)<br />
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py", line 1141, in _jvp_with_argnums<br />
    result_duals = func(*duals)<br />
  File "/home/cwtan/florch/tests/test.py", line 6, in func<br />
    return two * x</p>
<p>Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information</p>
<p>You can suppress this exception and fall back to eager by setting:<br />
    import torch._dynamo<br />
    torch._dynamo.config.suppress_errors = True<br />
```</p>
<p>For the second example where <code>two = torch.tensor([2.0], dtype=x.dtype, device=x.device)</code>.<br />
<code>Traceback (most recent call last):
  File "/home/cwtan/florch/tests/test.py", line 14, in &lt;module&gt;
    compiled_jac_func(torch.ones((3,), dtype=torch.float64))
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 403, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 977, in catch_errors
    return callback(frame, cache_entry, hooks, frame_state, skip=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 818, in _convert_frame
    result = inner_convert(
             ^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 411, in _convert_frame_assert
    return _compile(
           ^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_utils_internal.py", line 70, in wrapper_function
    return function(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 700, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 268, in time_wrapper
    r = func(*args, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 568, in compile_inner
    out_code = transform_code_object(code, transform)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py", line 1116, in transform_code_object
    transformations(instructions, code_options)
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 173, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 515, in transform
    tracer.run()
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2237, in run
    super().run()
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 875, in run
    while self.step():
          ^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 790, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2394, in RETURN_VALUE
    self._return(inst)
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py", line 2379, in _return
    self.output.compile_subgraph(
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/output_graph.py", line 1091, in compile_subgraph
    self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/output_graph.py", line 1283, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 268, in time_wrapper
    r = func(*args, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/output_graph.py", line 1374, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/output_graph.py", line 1355, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.example_inputs())
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/repro/after_dynamo.py", line 127, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/__init__.py", line 1744, in __call__
    return compile_fx(model_, inputs_, config_patches=self.config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_inductor/compile_fx.py", line 1434, in compile_fx
    return aot_autograd(
           ^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/backends/common.py", line 65, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py", line 958, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 268, in time_wrapper
    r = func(*args, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py", line 558, in create_aot_dispatcher_function
    fw_metadata = run_functionalized_fw_and_collect_metadata(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cwtan/anaconda3/envs/florch/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py", line 262, in inner
    curr_storage = StorageWeakRef(o.untyped_storage())
                                  ^^^^^^^^^^^^^^^^^^^
torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
NotImplementedError: Cannot access storage of TensorWrapper</code></p>
<h3>Minified repro</h3>
<p><em>No response</em></p>
<h3>Versions</h3>
<p>```<br />
Collecting environment information...<br />
PyTorch version: 2.4.0.dev20240425+cu121<br />
Is debug build: False<br />
CUDA used to build PyTorch: 12.1<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.2 LTS (x86_64)<br />
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br />
Clang version: Could not collect<br />
CMake version: Could not collect<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0] (64-bit runtime)<br />
Python platform: Linux-5.15.146.1-microsoft-standard-WSL2-x86_64-with-glibc2.35<br />
Is CUDA available: True<br />
CUDA runtime version: Could not collect<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: NVIDIA RTX A1000 6GB Laptop GPU<br />
Nvidia driver version: 537.77<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                       x86_64<br />
CPU op-mode(s):                     32-bit, 64-bit<br />
Address sizes:                      46 bits physical, 48 bits virtual<br />
Byte Order:                         Little Endian<br />
CPU(s):                             20<br />
On-line CPU(s) list:                0-19<br />
Vendor ID:                          GenuineIntel<br />
Model name:                         13th Gen Intel(R) Core(TM) i7-13800H<br />
CPU family:                         6<br />
Model:                              186<br />
Thread(s) per core:                 2<br />
Core(s) per socket:                 10<br />
Socket(s):                          1<br />
Stepping:                           2<br />
BogoMIPS:                           5836.80<br />
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves avx_vnni umip waitpkg gfni vaes vpclmulqdq rdpid movdiri movdir64b fsrm md_clear serialize flush_l1d arch_capabilities<br />
Virtualization:                     VT-x<br />
Hypervisor vendor:                  Microsoft<br />
Virtualization type:                full<br />
L1d cache:                          480 KiB (10 instances)<br />
L1i cache:                          320 KiB (10 instances)<br />
L2 cache:                           12.5 MiB (10 instances)<br />
L3 cache:                           24 MiB (1 instance)<br />
Vulnerability Gather data sampling: Not affected<br />
Vulnerability Itlb multihit:        Not affected<br />
Vulnerability L1tf:                 Not affected<br />
Vulnerability Mds:                  Not affected<br />
Vulnerability Meltdown:             Not affected<br />
Vulnerability Mmio stale data:      Not affected<br />
Vulnerability Retbleed:             Mitigation; Enhanced IBRS<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp<br />
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:           Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence<br />
Vulnerability Srbds:                Not affected<br />
Vulnerability Tsx async abort:      Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] flake8==7.0.0<br />
[pip3] mypy-extensions==1.0.0<br />
[pip3] numpy==1.26.4<br />
[pip3] pytorch-triton==3.0.0+45fff310c8<br />
[pip3] torch==2.4.0.dev20240425+cu121<br />
[pip3] torch-nl==0.3<br />
[conda] numpy                     1.26.4                   pypi_0    pypi<br />
[conda] pytorch-triton            3.0.0+45fff310c8          pypi_0    pypi<br />
[conda] torch                     2.4.0.dev20240425+cu121          pypi_0    pypi<br />
[conda] torch-nl                  0.3                      pypi_0    pypi<br />
```</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @chauhang</p>]]></description>
      <pubDate>Fri, 26 Apr 2024 14:12:45 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/125078</guid>
    </item>
    <item>
      <title>[1/N] Scalar Support: Enable aot compile to support aten operations with scalar input like alpha</title>
      <link>https://github.com/pytorch/pytorch/pull/124177</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #124926<br />
* #124070<br />
* <strong>-&gt;</strong> #124177<br />
* #116368<br />
* #124836</p>
<p>Some operations have a scalar input parameter, like <code>torch.add(a, b, alpha=2.0)</code>.  Currently, the aot compile does not support such a case because it requires the signature of the captured graph to align with the operation's signature. This means that some inputs in the captured graph may be scalar(float, int, bool, etc.). It breaks the assumption of <code>compile_fx_aot</code> as it assumes all the example inputs are tensor - https://github.com/pytorch/pytorch/blob/0f6ce45bcbd7026c00da43db0317ede10830378b/torch/_inductor/compile_fx.py#L1048</p>
<p>This PR intends to support such cases by allowing not-aligned signature and filtering out the non-Tensor parameters. </p>
<p>Captured graph for <code>torch.add(a, b, alpha=2.0)</code></p>
<p>```<br />
opcode         name      target           args              kwargs</p>
<hr />
<p>placeholder    arg0_1    arg0_1           ()                {}<br />
placeholder    arg1_1    arg1_1           ()                {}<br />
call_function  add       aten.add.Tensor  (arg0_1, arg1_1)  {'alpha': 2.0}<br />
output         output_1  output           ((add,),)         {}<br />
```</p>
<p>cc @voznesenskym @penguinwu @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 16 Apr 2024 07:05:26 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/124177</guid>
    </item>
    <item>
      <title>[WIP] [Inductor Intel GPU backend Upstream] Reuse inductor test for Intel GPU (PART 2)</title>
      <link>https://github.com/pytorch/pytorch/pull/124147</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #124702<br />
* <strong>-&gt;</strong> #124147<br />
* #122866</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Mon, 15 Apr 2024 21:37:38 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/124147</guid>
    </item>
    <item>
      <title>[2/N] Scalar Support: Add scalar to the cache for eager-through-torch.compile</title>
      <link>https://github.com/pytorch/pytorch/pull/124070</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #124926<br />
* <strong>-&gt;</strong> #124070<br />
* #124177<br />
* #116368<br />
* #124836</p>
<p>Add scalar information to the kernel configuration.</p>
<h4>Additional Context</h4>
<p>Currently, the input parameters are orchestrated by input order in the kernel configuration and loaded/mapped to the kernel at runtime. For example, the cache order of the input parameters of <code>torch.add(a, b, alpha=2.0)</code> is <code>a' first, followed by</code>b<code>and then</code>alpha`. The same order is for cache loading.</p>
<p>However, the orchestration mechanism does not support kwargs because the order of kwargs is useless. For example, the <code>out</code> of <code>aten::gelu.out(Tensor self, *, str approximate='none', Tensor(a!) out) -&gt; Tensor(a!)</code> may be before <code>approximate</code>. We will support it with subsequent PRs. </p>
<p>cc @voznesenskym @penguinwu @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Mon, 15 Apr 2024 07:04:35 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/124070</guid>
    </item>
    <item>
      <title>[inductor][cpp] GEMM template</title>
      <link>https://github.com/pytorch/pytorch/pull/124021</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #124021</p>
<p>cc @voznesenskym @penguinwu @EikanWang @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Sun, 14 Apr 2024 06:21:12 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/124021</guid>
    </item>
    <item>
      <title>Add a cache mechanism to accelerate torch.compile-for-eager</title>
      <link>https://github.com/pytorch/pytorch/pull/116368</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #124926<br />
* #124070<br />
* #124177<br />
* <strong>-&gt;</strong> #116368<br />
* #124836</p>
<p>This PR is a follow-up of RFC https://github.com/pytorch/pytorch/issues/115545.</p>
<p>In this PR, we are trying to enable a cache mechanism to accelerate <strong>eager-through-torch.compile</strong>. When <strong>eager-through-torch.compile</strong> is enabled, we will store a persistent config to cache the kernel information for the aten operation. </p>
<p>The persistent config consists of two parts - meta_info and kernel_path.</p>
<ul>
<li>meta_info: The input tensors' shape, stride, device type, data type, and symbolic flag.</li>
<li>kernel_path: The path of the kernel produced by Inductor.</li>
</ul>
<p>When an aten operation is registered, the <code>kernel_holder</code> will load the persistent config and parse it to build the cache map;  the meta_info is key, and the kernel library is the value.</p>
<p>Currently, this PR only supports static shape to guard the kernel.</p>
<p>Take a <code>mul</code> as an example.<br />
```python<br />
class MulKernel:<br />
  def <strong>init</strong>(self) -&gt; None:<br />
    pass</p>
<p>def <strong>call</strong>(self, <em>args: Any, </em><em>kwargs: Any) -&gt; Any:<br />
    with torch._C._SetExcludeDispatchKeyGuard(torch._C.DispatchKey.Python, False):<br />
      opt_fn = torch.compile(torch.ops.aten.mul, dynamic=False, options={<br />
          "aot_inductor.eager_mode": True,<br />
          "aot_inductor.eager_op_name": "mul_Tensor"<br />
        }<br />
      )<br />
      return opt_fn(</em>args, **kwargs)</p>
<p>torch_compile_op_lib_impl = torch.library.Library("aten", "IMPL")</p>
<p>_, overload_names = torch._C._jit_get_operation("aten::mul")<br />
schema = torch._C._get_schema("aten::mul", overload_name)<br />
reg_name = schema.name<br />
if schema.overload_name:<br />
  reg_name = f"{reg_name}.{schema.overload_name}"<br />
  torch_compile_op_lib_impl.impl(<br />
    reg_name,<br />
    MulKernel(),<br />
    "CUDA",<br />
    compile_mode=True)</p>
<p>a = torch.randn(1024, 1024, device=device)<br />
b = torch.randn(1024, 1024, device=device)<br />
warm_up_iter = 1000<br />
iter = 10000<br />
fn = torch.mul</p>
<h1>Warm up</h1>
<p>for _ in range(warm_up_iter):<br />
    fn(a, b)</p>
<h1>Collect performance</h1>
<p>beg = time.time()<br />
for _ in range(iter):<br />
    fn(a, b)<br />
end = time.time()<br />
print(f"E2E run: {end - beg}")<br />
```<br />
It will produce the config as follows.</p>
<p><code>json
[
    {
        "meta_info": [
            {
                "is_symbolic": "false",
                "device_type": "cuda",
                "dtype": "torch.float32",
                "sizes": "[1024, 1024]",
                "strides": "[1024, 1]"
            },
            {
                "is_symbolic": "false",
                "device_type": "cuda",
                "dtype": "torch.float32",
                "sizes": "[1024, 1024]",
                "strides": "[1024, 1]"
            }
        ],
        "kernel_path": "/tmp/torchinductor_eikan/e4/ce4jw46i5l2e7v3tvr2pyglpjmahnp7x3hxaqotrvxwoeh5t6qzc.so"
    }
]</code></p>
<p>Performance-wise, we collected mul.Tensor through torch.compile w/ 10000 runs(e2e). The data is as follows. And we will collect data when we support dynamic shape.</p>
<ul>
<li>Eager: ~266.11ms</li>
<li>W/O Cache: ~3455.54ms</li>
<li>W/ Cache and Cache Miss: ~3555.3ms</li>
<li>W/ Cache and Cache Hit: ~267.12ms</li>
</ul>
<p>Hardware:</p>
<ul>
<li>CPU: Intel(R) Xeon(R) Platinum 8260 CPU @ 2.40GHz</li>
<li>GPU: CUDA A10</li>
</ul>
<p>Software:</p>
<ul>
<li>PyTorch Version: 39df084001c54cca5fe3174176f9b0206ddb7dcf</li>
<li>GPU Driver Version: 525.147.05</li>
<li>CUDA Version: 12.0</li>
</ul>
<p>cc @voznesenskym @penguinwu @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Sun, 24 Dec 2023 03:21:18 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/116368</guid>
    </item>
  </channel>
</rss>
