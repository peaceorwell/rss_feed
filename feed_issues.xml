<?xml version='1.0' encoding='UTF-8'?>
<rss version="2.0">
  <channel>
    <title>GitHub issues Feed</title>
    <link>https://github.com/username/repo/issues</link>
    <description>Recent issues from GitHub repo</description>
    <item>
      <title>[aot_inductor][easy] enable test_triton_kernel_multi_output_arg</title>
      <link>https://github.com/pytorch/pytorch/pull/122052</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122052</p>
<p>looks like we already support aoti_torch_cuda_sort in C shim.</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Sun, 17 Mar 2024 01:46:10 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122052</guid>
    </item>
    <item>
      <title>[RFC] Use CUDA graphs by default on torch.compile</title>
      <link>https://github.com/pytorch/pytorch/issues/121968</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>I keep seeing comparisons between JAX / TF / Keras vs <code>torch.compile</code> where they benchmark the "default XLA settings vs. the default <code>torch.compile</code>" to find that XLA frontends are x3-x4 faster than <code>torch.compile</code>.<br />
The last one I found is the newly posted Keras 3 benchmarks<br />
https://keras.io/getting_started/benchmarks/ <br />
but I have seen these skewed comparisons over and over again.</p>
<p>The only thing stopping us from compiling with CUDA graphs on is that these sometimes have a higher mem footprint. Would it be reasonable to turn these on by default so that people get speed by default, and then catch a potential OOM and re-raise it indicating that using CUDA-graphs off to potentialy mitigate the OOM?</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @jansel @albanD @eellison @Chillee </p>
<h3>Versions</h3>
<p>master</p>]]></description>
      <pubDate>Fri, 15 Mar 2024 05:32:36 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/121968</guid>
    </item>
  </channel>
</rss>
