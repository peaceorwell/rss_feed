<?xml version='1.0' encoding='UTF-8'?>
<rss version="2.0">
  <channel>
    <title>GitHub issues Feed</title>
    <link>https://github.com/username/repo/issues</link>
    <description>Recent issues from GitHub repo</description>
    <item>
      <title>Higher peak memory with torch.compile</title>
      <link>https://github.com/pytorch/pytorch/issues/122512</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>If I fuse the backward with compiled forward+loss, there's a higher peak memory than if I separate the backward from compiled forward+loss. It looks like the logits aren't being cleared.</p>
<p>Fused forward+loss+backward:<br />
```<br />
@torch.compile<br />
def fused_forward_and_loss_and_backward(input_ids, labels):<br />
    logits = model.forward(input_ids)<br />
    loss = F.cross_entropy(logits.view(-1, logits.shape[-1]).float(), labels.view(-1))<br />
    # del logits # doesn't change peak memory<br />
    loss.backward()<br />
    return loss<br />
...</p>
<h1>usage:</h1>
<p>loss = fused_forward_and_loss_and_backward(batch_input_ids, gas_labels)<br />
print("peak memory usage", torch.cuda.max_memory_allocated())<br />
<code>Results:</code><br />
peak memory usage 22139266048 (first step)<br />
peak memory usage 23943063552 (second step)<br />
peak memory usage 23943063552 (third step)<br />
```</p>
<p>Fused forward+loss, separated backward:</p>
<p>```<br />
@torch.compile<br />
def fused_forward_and_loss(input_ids, labels):<br />
    logits = model.forward(input_ids)<br />
    loss = F.cross_entropy(logits.view(-1, logits.shape[-1]).float(), labels.view(-1))<br />
    # loss.backward() # no backward here!<br />
    return loss<br />
...</p>
<h1>usage:</h1>
<p>loss = fused_forward_and_loss(batch_input_ids, gas_labels)<br />
loss.backward()<br />
print("peak memory usage", torch.cuda.max_memory_allocated())<br />
```</p>
<p>Results:<br />
<code>peak memory usage 19991782400
peak memory usage 21795579392
peak memory usage 21795579392</code></p>
<p>Memory traces:<br />
https://drive.google.com/file/d/18UywAfWmBDNJMzbCy44KVUy6qCug3cxX/view?usp=sharing<br />
https://drive.google.com/file/d/1A0Cu9fAbJS1dbzBJvRmm-0U1ygsmtT9W/view?usp=sharing</p>
<h3>Error logs</h3>
<p><em>No response</em></p>
<h3>Minified repro</h3>
<p><em>No response</em></p>
<h3>Versions</h3>
<p>Collecting environment information...<br />
PyTorch version: 2.2.0<br />
Is debug build: False<br />
CUDA used to build PyTorch: 12.2<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.4 LTS (x86_64)<br />
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br />
Clang version: Could not collect<br />
CMake version: version 3.28.3<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0] (64-bit runtime)<br />
Python platform: Linux-5.19.17-coreweave-x86_64-with-glibc2.35<br />
Is CUDA available: True<br />
CUDA runtime version: 12.2.140<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: NVIDIA A40<br />
Nvidia driver version: 535.161.07<br />
cuDNN version: Probably one of the following:<br />
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.6<br />
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.6<br />
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.6<br />
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.6<br />
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.6<br />
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.6<br />
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.6<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                    x86_64<br />
CPU op-mode(s):                  32-bit, 64-bit<br />
Address sizes:                   48 bits physical, 48 bits virtual<br />
Byte Order:                      Little Endian<br />
CPU(s):                          96<br />
On-line CPU(s) list:             0-95<br />
Vendor ID:                       AuthenticAMD<br />
Model name:                      AMD EPYC 7413 24-Core Processor<br />
CPU family:                      25<br />
Model:                           1<br />
Thread(s) per core:              2<br />
Core(s) per socket:              24<br />
Socket(s):                       2<br />
Stepping:                        1<br />
Frequency boost:                 enabled<br />
CPU max MHz:                     3630.8101<br />
CPU min MHz:                     1500.0000<br />
BogoMIPS:                        5299.98<br />
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin brs arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm<br />
Virtualization:                  AMD-V<br />
L1d cache:                       1.5 MiB (48 instances)<br />
L1i cache:                       1.5 MiB (48 instances)<br />
L2 cache:                        24 MiB (48 instances)<br />
L3 cache:                        256 MiB (8 instances)<br />
NUMA node(s):                    2<br />
NUMA node0 CPU(s):               0-23,48-71<br />
NUMA node1 CPU(s):               24-47,72-95<br />
Vulnerability Itlb multihit:     Not affected<br />
Vulnerability L1tf:              Not affected<br />
Vulnerability Mds:               Not affected<br />
Vulnerability Meltdown:          Not affected<br />
Vulnerability Mmio stale data:   Not affected<br />
Vulnerability Retbleed:          Not affected<br />
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl<br />
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected<br />
Vulnerability Srbds:             Not affected<br />
Vulnerability Tsx async abort:   Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.26.4<br />
[pip3] torch==2.2.0<br />
[pip3] torchaudio==2.2.0<br />
[pip3] torchvision==0.17.0<br />
[pip3] triton==2.2.0<br />
[conda] Could not collect</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang</p>]]></description>
      <pubDate>Fri, 22 Mar 2024 10:41:05 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122512</guid>
    </item>
    <item>
      <title>[CPUInductor] Fix out-of-bounds read/write in cvt_int64_to_fp32</title>
      <link>https://github.com/pytorch/pytorch/pull/122511</link>
      <description><![CDATA[<p>Discovered while debugging regressions in enabling vectorization on ARM platform</p>
<p>Without this change <code>test_div2_cpu</code> will fail with invalid values on non-x86 CPU</p>]]></description>
      <pubDate>Fri, 22 Mar 2024 10:36:43 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122511</guid>
    </item>
    <item>
      <title>compile: ban mutations on non-compositional uses of as_strided</title>
      <link>https://github.com/pytorch/pytorch/pull/122502</link>
      <description><![CDATA[<p>Fixes https://github.com/pytorch/pytorch/issues/104505</p>
<p>I was originally going to ban all usages of as_strided + mutation in functionalization. But I'm pretty sure that as_strided + mutation is fine when we are calling as_strided on a base tensor.</p>
<p>So in this PR I added a slightly more conservative check: if we see an as_strided + mutation, where the input to an as_strided was <strong>another</strong> view op, then I error loudly in functionalization and link to the github issue above (in case anyone runs into this in the real world)</p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122502<br />
* #118802<br />
* #118670</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @chenyang78 @kadeng @chauhang</p>]]></description>
      <pubDate>Fri, 22 Mar 2024 08:15:38 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122502</guid>
    </item>
    <item>
      <title>[Inductor] Pass device interface to the worker compile</title>
      <link>https://github.com/pytorch/pytorch/pull/122492</link>
      <description><![CDATA[<p>Summary: In <code>codecache.py</code> pass the device_interface directly to <code>_worker_compile()</code> instead of calling <code>get_device_interface()</code> from inside the function.</p>
<p>If the device_interface is registered by an out-of-tree module then it will only be registered inside the main process and not inside the worker process. This fixes this issue. Happy to add a test if required. </p>
<p>Test plan:<br />
No tests added</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Fri, 22 Mar 2024 04:05:21 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122492</guid>
    </item>
    <item>
      <title>[inductor][cpu] maml_omniglot AMP Dynamic shape default wrapper accuracy and performance crashed</title>
      <link>https://github.com/pytorch/pytorch/issues/122489</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>maml_omniglot AMP Dynamic shape default wrapper accuracy and performance crashed</p>
<table border="1" class="dataframe table">
  <thead>
    <tr style="text-align: right;">
      <th>suite</th>
      <th>name</th>
      <th>thread</th>
      <th>accuracy</th>
      <th>perf</th>
      <th>reason(reference only)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>torchbench</td>
      <td>maml_omniglot</td>
      <td>multiple</td>
      <td>X</td>
      <td>N/A</td>
      <td>maml_omniglot, AssertionError: expected size 64==64  stride 1==676 at dim=1</td>
    </tr>
    <tr>
      <td>torchbench</td>
      <td>maml_omniglot</td>
      <td>single</td>
      <td>X</td>
      <td>N/A</td>
      <td>maml_omniglot, AssertionError: expected size 64==64  stride 1==676 at dim=1</td>
    </tr>
  </tbody>

</table>

<p>```<br />
loading model: 0it [00:00, ?it/s]cpu  eval  maml_omniglot                      </p>
<p>skipping cudagraphs due to skipping cudagraphs due to cpu device. Found from : <br />
   File "benchmarks/dynamo/torchbench.py", line 357, in forward_pass<br />
    return mod(*inputs)</p>
<p>ERROR:common:Backend dynamo failed in warmup()<br />
Traceback (most recent call last):<br />
  File "/workspace/pytorch/benchmarks/dynamo/common.py", line 2639, in warmup<br />
    fn(model, example_inputs)<br />
  File "/workspace/pytorch/torch/_dynamo/eval_frame.py", line 390, in _fn<br />
    return fn(<em>args, </em><em>kwargs)<br />
  File "benchmarks/dynamo/torchbench.py", line 355, in forward_pass<br />
    def forward_pass(self, mod, inputs, collect_outputs=True):<br />
  File "/workspace/pytorch/torch/_dynamo/eval_frame.py", line 390, in _fn<br />
    return fn(</em>args, <strong>kwargs)<br />
  File "/workspace/pytorch/torch/_dynamo/external_utils.py", line 36, in inner<br />
    return fn(*args, </strong>kwargs)<br />
  File "/workspace/pytorch/torch/_functorch/aot_autograd.py", line 917, in forward<br />
    return compiled_fn(full_args)<br />
  File "/workspace/pytorch/torch/_functorch/_aot_autograd/utils.py", line 89, in g<br />
    return f(*args)<br />
  File "/workspace/pytorch/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 106, in runtime_wrapper<br />
    all_outs = call_func_at_runtime_with_args(<br />
  File "/workspace/pytorch/torch/_functorch/_aot_autograd/utils.py", line 113, in call_func_at_runtime_with_args<br />
    out = normalize_as_list(f(args))<br />
  File "/workspace/pytorch/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 152, in rng_functionalization_wrapper<br />
    return compiled_fw(args)<br />
  File "/workspace/pytorch/torch/_inductor/compile_fx.py", line 1093, in wrapper<br />
    return optimized_function(args_new)<br />
  File "/workspace/pytorch/torch/_inductor/codecache.py", line 937, in <strong>call</strong><br />
    return self.current_callable(inputs)<br />
  File "/tmp/tmp2dbylmum/b6/cb6xejcvhq24bivlii5l4bnrokyshg25eaegfundva3emkz5hllr.py", line 251, in call<br />
    assert_size_stride(buf1, (s0, 64, 26, 26), (43264, 676, 26, 1))<br />
AssertionError: expected size 64==64, stride 1==676 at dim=1<br />
Run failed with return code:  255<br />
Output:  None<br />
Error:  None<br />
```</p>
<h3>Versions</h3>
<p></table><p>SW info</p><table border="1" class="dataframe table"><br />
<br />
<thead>
    <tr style="text-align: right;">
      <th>name</th>
      <th>target_branch</th>
      <th>target_commit</th>
      <th>refer_branch</th>
      <th>refer_commit</th>
    </tr>
  </thead></p>
<tbody>
    <tr>
      <td>torchbench</td>
      <td>main</td>
      <td>d6015d42</td>
      <td>main</td>
      <td>1ef0a39e</td>
    </tr>
    <tr>
      <td>torch</td>
      <td>main</td>
      <td>5bc7f7f97760d2d485621f9f30d0316e1f2440c6</td>
      <td>main</td>
      <td>41286f1505ffb214d386d72e4b72ebd680a4a475</td>
    </tr>
    <tr>
      <td>torchvision</td>
      <td>main</td>
      <td>0.18.0a0+0325175</td>
      <td>main</td>
      <td>0.18.0a0+2c127da</td>
    </tr>
    <tr>
      <td>torchtext</td>
      <td>main</td>
      <td>0.16.0a0+b0ebddc</td>
      <td>main</td>
      <td>0.16.0a0+b0ebddc</td>
    </tr>
    <tr>
      <td>torchaudio</td>
      <td>main</td>
      <td>2.2.0a0+87aeb55</td>
      <td>main</td>
      <td>2.2.0a0+87aeb55</td>
    </tr>
    <tr>
      <td>torchdata</td>
      <td>main</td>
      <td>0.7.1a0+0790338</td>
      <td>main</td>
      <td>0.7.1a0+0790338</td>
    </tr>
    <tr>
      <td>dynamo_benchmarks</td>
      <td>main</td>
      <td>nightly</td>
      <td>main</td>
      <td>nightly</td>
    </tr>
  </tbody>
</table>
<p>Repro:<br />
<a href="https://github.com/chuanqi129/inductor-tools/blob/main/scripts/modelbench/inductor_single_run.sh">inductor_single_run.sh</a><br />
bash inductor_single_run.sh <strong>thread</strong> inference accuracy/performance torchbench maml_omniglot AMP first dynamic default 0</p>
<p>Suspected guilty commit: https://github.com/pytorch/pytorch/commit/f2f8eeea944f5cc6dd6f907a0c78067f73e0ad9c<br />
<a href="https://github.com/pytorch/pytorch/files/14719691/torchbench-maml_omniglot-inference-amp-dynamic-default-single-accuracy-crash_guilty_commit.log">torchbench-maml_omniglot-inference-amp-dynamic-default-single-accuracy-crash_guilty_commit.log</a><br />
cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @WeizhuoZhang-intel @chuanqi129</p>]]></description>
      <pubDate>Fri, 22 Mar 2024 00:26:51 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122489</guid>
    </item>
    <item>
      <title>[Quant] [PT2] Add EmbeddingBag  into X86InductorQuantizer Annotation</title>
      <link>https://github.com/pytorch/pytorch/pull/122488</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122488</p>]]></description>
      <pubDate>Fri, 22 Mar 2024 00:11:24 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122488</guid>
    </item>
    <item>
      <title>AOTInductor Does Not Recompile when Saving at Same Path Even if Model Definition Changes</title>
      <link>https://github.com/pytorch/pytorch/issues/122487</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>When compiling a model twice to the same path, AOTInductor does not recompile the library. Instead, the first compile <code>model.so</code> file remains, even when the model definition has been changing. </p>
<h2>Reproduce</h2>
<p>There are two ways to reproduce this: <br />
1) Run the <a href="https://pytorch.org/docs/stable/torch.compiler_aot_inductor.html">AOTInductor example</a>  twice at two different times and verify that the second compiled model has the same timestamp as the first run<br />
2) Run the example below which contains two different models. The results produced by these models differ, but the hash value of the compiled shared model differs:<br />
```Python<br />
import os<br />
import hashlib<br />
import torch</p>
<p>class Model(torch.nn.Module):<br />
    def <strong>init</strong>(self):<br />
        super().<strong>init</strong>()<br />
        self.relu = torch.nn.ReLU()</p>
<pre><code>def forward(self, x):
    x = self.relu(x)
    return x
</code></pre>
<p>class Model2(torch.nn.Module):<br />
    def <strong>init</strong>(self):<br />
        super().<strong>init</strong>()<br />
        self.relu = torch.nn.ReLU()<br />
        self.sigmoid = torch.nn.Sigmoid()</p>
<pre><code>def forward(self, x):
    x = self.relu(x)
    x = self.sigmoid(x)
    return x
</code></pre>
<p>with torch.no_grad():<br />
    device = "cuda" if torch.cuda.is_available() else "cpu"<br />
    example_inputs=(torch.randn(8, 10, device=device),)<br />
    batch_dim = torch.export.Dim("batch", min=1, max=1024)</p>
<pre><code># Model 1 ##
model = Model().to(device=device)
so_path = torch._export.aot_compile(
    model,
    example_inputs,
    # Specify the first dimension of the input x as dynamic
    dynamic_shapes={"x": {0: batch_dim}},
    # Specify the generated shared library path
    options={"aot_inductor.output_path": "/tmp/exported/model.so"},
)
res1 = model(*example_inputs)
hashval1 = hashlib.md5(open(so_path, 'rb').read()).hexdigest()

## Model 2 ## 
model2 = Model2().to(device=device)
so_path = torch._export.aot_compile(
    model2,
    example_inputs,
    # Specify the first dimension of the input x as dynamic
    dynamic_shapes={"x": {0: batch_dim}},
    # Specify the generated shared library path
    options={"aot_inductor.output_path": "/tmp/exported/model.so"},
)
res2 = model2(*example_inputs)
hashval2 = hashlib.md5(open(so_path, 'rb').read()).hexdigest()

assert res1.sum() != res2.sum(), "results are different"
assert hashval1 != hashval2, "hash musht be different"
</code></pre>
<p>``` <br />
If the compiled libraries are saved at two different paths, the hashvalues differ. </p>
<h3>Versions</h3>
<p>Collecting environment information...<br />
PyTorch version: 2.2.1+cu121<br />
Is debug build: False<br />
CUDA used to build PyTorch: 12.1<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.4 LTS (x86_64)<br />
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br />
Clang version: Could not collect<br />
CMake version: version 3.28.3<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.10.13 (main, Sep  5 2023, 06:03:44) [GCC 11.4.0] (64-bit runtime)<br />
Python platform: Linux-6.2.0-35-generic-x86_64-with-glibc2.35<br />
Is CUDA available: True<br />
CUDA runtime version: Could not collect<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: Quadro T1000<br />
Nvidia driver version: 535.161.07<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                       x86_64<br />
CPU op-mode(s):                     32-bit, 64-bit<br />
Address sizes:                      39 bits physical, 48 bits virtual<br />
Byte Order:                         Little Endian<br />
CPU(s):                             12<br />
On-line CPU(s) list:                0-11<br />
Vendor ID:                          GenuineIntel<br />
Model name:                         Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz<br />
CPU family:                         6<br />
Model:                              158<br />
Thread(s) per core:                 2<br />
Core(s) per socket:                 6<br />
Socket(s):                          1<br />
Stepping:                           10<br />
CPU max MHz:                        4500,0000<br />
CPU min MHz:                        800,0000<br />
BogoMIPS:                           5199.98<br />
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust sgx bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp sgx_lc md_clear flush_l1d arch_capabilities<br />
Virtualization:                     VT-x<br />
L1d cache:                          192 KiB (6 instances)<br />
L1i cache:                          192 KiB (6 instances)<br />
L2 cache:                           1,5 MiB (6 instances)<br />
L3 cache:                           12 MiB (1 instance)<br />
NUMA node(s):                       1<br />
NUMA node0 CPU(s):                  0-11<br />
Vulnerability Gather data sampling: Mitigation; Microcode<br />
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled<br />
Vulnerability L1tf:                 Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable<br />
Vulnerability Mds:                  Mitigation; Clear CPU buffers; SMT vulnerable<br />
Vulnerability Meltdown:             Mitigation; PTI<br />
Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable<br />
Vulnerability Retbleed:             Mitigation; IBRS<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl<br />
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:           Mitigation; IBRS, IBPB conditional, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected<br />
Vulnerability Srbds:                Mitigation; Microcode<br />
Vulnerability Tsx async abort:      Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] fast-pytorch-kmeans==0.2.0.1<br />
[pip3] flake8==6.0.0<br />
[pip3] mypy==1.4.1<br />
[pip3] mypy-extensions==1.0.0<br />
[pip3] numpy==1.26.4<br />
[pip3] pytorch-triton==2.1.0+3c400e7818<br />
[pip3] torch==2.2.1<br />
[pip3] torch-tb-profiler==0.4.1<br />
[pip3] torchaudio==2.1.0.dev20230714+cu121<br />
[pip3] torchdata==0.7.0<br />
[pip3] torchprofile==0.0.4<br />
[pip3] torchtext==0.16.0<br />
[pip3] torchvision==0.17.1<br />
[pip3] triton==2.2.0<br />
[conda] Could not collect</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @chenyang78 @kadeng @desertfire</p>]]></description>
      <pubDate>Thu, 21 Mar 2024 23:59:25 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122487</guid>
    </item>
    <item>
      <title>compile: mutations under no_grad might not be included in the graph when they are on aliases</title>
      <link>https://github.com/pytorch/pytorch/issues/122436</link>
      <description><![CDATA[<p>Simple repro (came from tracing ppFSDP work):<br />
<code>def f(a):
            a_alias = a.view(-1)
            with torch.no_grad():
                a_alias.mul_(2)
            return a + 1
        inp = torch.ones(4, requires_grad=True)
        out = torch.compile(f)(inp)</code></p>
<p>Running this with <code>TORCH_LOGS="aot", you will se that there is not a</code>copy_()` in the graph - this means that it is hidden outside of the graph, and run in an opaque runtime epilogue.</p>
<p>This mutations should be safe to include in the graph - since it is under no_grad, no autograd metadata needs to be updated (except for the version counter of a, which AOTAutograd handles today directly).</p>
<p>cc @ezyang @msaroufim @anijain2305 @zou3519 @chauhang</p>]]></description>
      <pubDate>Thu, 21 Mar 2024 12:58:37 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122436</guid>
    </item>
    <item>
      <title>[inductor] Fix issue with randint + symbolic shapes</title>
      <link>https://github.com/pytorch/pytorch/pull/122428</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122428</p>
<p>Fixes #122405</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Thu, 21 Mar 2024 11:20:29 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122428</guid>
    </item>
    <item>
      <title> [Inductor] Add a test for creating a cpu inductor-&gt; triton backend</title>
      <link>https://github.com/pytorch/pytorch/pull/122396</link>
      <description><![CDATA[<p>Summary: Currently there is a test for adding a backend in test/inductor/test_extension_backend.py for a cpp backend with a new device. However there is no such test for the Triton backend; it should be possible for a user to create and register your own ExtensionWrapperCodegen and ExtensionSchedulingfor another non-CUDA device and be able to generate Triton code. For simplicity I have chosen to use a CPU device, as I think it's plausible someone might want to create a CPU Triton backend.</p>
<p>Unfortunately the generation and running of the code is quite tightly coupled so I've had to use a mocked function to extract the code before running. Suggestions are welcome for better ways to do this.</p>
<p>This is a stepping off point for some additional PRs to make the Triton code path less CUDA specific, as currently there would be no way to test this avenue.</p>
<p>Test plan:<br />
```<br />
frames [('total', 1), ('ok', 1)]<br />
stats [('calls_captured', 3), ('unique_graphs', 1)]<br />
inductor [('intermediate_hooks', 1)]<br />
aot_autograd [('total', 1), ('ok', 1)]<br />
.</p>
<hr />
<p>Ran 1 test in 0.394s<br />
```</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Thu, 21 Mar 2024 03:38:01 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122396</guid>
    </item>
    <item>
      <title>[torch.compile] `conv_add` optimization will omit the `alpha` argument</title>
      <link>https://github.com/pytorch/pytorch/issues/122382</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>The <code>conv_add</code> optimization overlooks the <code>alpha</code> parameter. In the model provided, the <code>torch.compile</code> method assumes <code>alpha=1</code> by default, whereas the actual value of <code>alpha</code> is 0.85. This discrepancy leads to a variation in the output compared to a straightforward execution.</p>
<p>```py<br />
import torch</p>
<p>torch.manual_seed(420)</p>
<p>class Model(torch.nn.Module):</p>
<pre><code>def __init__(self):
    super().__init__()
    self.conv = torch.nn.Conv2d(3, 2, 1, stride=1, padding=1)
    self.other_tensor = torch.randn(2, 1, 1)

def forward(self, x1):
    v1 = self.conv(x1)
    v2 = torch.add(v1, self.other_tensor, alpha=0.875)
    return v2
</code></pre>
<p>func = Model().to('cpu')</p>
<p>x = torch.randn(1, 3, 2, 2)</p>
<p>with torch.no_grad():<br />
    print(func(x.clone()))</p>
<pre><code>func1 = torch.compile(func)
print(func1(x.clone()))

print(torch.allclose(func.other_tensor, func1.other_tensor)) # True
</code></pre>
<p>"""<br />
tensor([[[[ 1.7728,  1.7728,  1.7728,  1.7728],<br />
          [ 1.7728,  2.1860,  1.7604,  1.7728],<br />
          [ 1.7728,  0.9550,  2.3261,  1.7728],<br />
          [ 1.7728,  1.7728,  1.7728,  1.7728]],</p>
<pre><code>     [[ 0.2579,  0.2579,  0.2579,  0.2579],
      [ 0.2579, -0.5048,  0.6618,  0.2579],
      [ 0.2579,  0.9659,  0.0888,  0.2579],
      [ 0.2579,  0.2579,  0.2579,  0.2579]]]])
</code></pre>
<p>tensor([[[[ 1.9624,  1.9624,  1.9624,  1.9624],<br />
          [ 1.9624,  2.3757,  1.9500,  1.9624],<br />
          [ 1.9624,  1.1447,  2.5158,  1.9624],<br />
          [ 1.9624,  1.9624,  1.9624,  1.9624]],</p>
<pre><code>     [[ 0.2639,  0.2639,  0.2639,  0.2639],
      [ 0.2639, -0.4989,  0.6677,  0.2639],
      [ 0.2639,  0.9718,  0.0947,  0.2639],
      [ 0.2639,  0.2639,  0.2639,  0.2639]]]])
</code></pre>
<p>"""<br />
```</p>
<h3>Versions</h3>
<p>```<br />
Collecting environment information...<br />
PyTorch version: 2.3.0.dev20240301+cu121<br />
Is debug build: False<br />
CUDA used to build PyTorch: 12.1<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.1 LTS (x86_64)<br />
GCC version: (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0<br />
Clang version: 11.0.0 (https://github.com/aflgo/aflgo.git fa125da5d70621daf7141c6279877c97708c8c1f)<br />
CMake version: version 3.22.1<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.9.0 (default, Nov 15 2020, 14:28:56)  [GCC 7.3.0] (64-bit runtime)<br />
Python platform: Linux-6.5.0-26-generic-x86_64-with-glibc2.35<br />
Is CUDA available: True<br />
CUDA runtime version: Could not collect<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3060<br />
Nvidia driver version: 525.147.05<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                       x86_64<br />
CPU op-mode(s):                     32-bit, 64-bit<br />
Address sizes:                      46 bits physical, 48 bits virtual<br />
Byte Order:                         Little Endian<br />
CPU(s):                             24<br />
On-line CPU(s) list:                0-23<br />
Vendor ID:                          GenuineIntel<br />
Model name:                         12th Gen Intel(R) Core(TM) i9-12900K<br />
CPU family:                         6<br />
Model:                              151<br />
Thread(s) per core:                 2<br />
Core(s) per socket:                 16<br />
Socket(s):                          1<br />
Stepping:                           2<br />
CPU max MHz:                        5200.0000<br />
CPU min MHz:                        800.0000<br />
BogoMIPS:                           6374.40<br />
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault cat_l2 cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect avx_vnni dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq tme rdpid movdiri movdir64b fsrm md_clear serialize pconfig arch_lbr ibt flush_l1d arch_capabilities<br />
Virtualization:                     VT-x<br />
L1d cache:                          640 KiB (16 instances)<br />
L1i cache:                          768 KiB (16 instances)<br />
L2 cache:                           14 MiB (10 instances)<br />
L3 cache:                           30 MiB (1 instance)<br />
NUMA node(s):                       1<br />
NUMA node0 CPU(s):                  0-23<br />
Vulnerability Gather data sampling: Not affected<br />
Vulnerability Itlb multihit:        Not affected<br />
Vulnerability L1tf:                 Not affected<br />
Vulnerability Mds:                  Not affected<br />
Vulnerability Meltdown:             Not affected<br />
Vulnerability Mmio stale data:      Not affected<br />
Vulnerability Retbleed:             Not affected<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl<br />
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:           Mitigation; Enhanced / Automatic IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence<br />
Vulnerability Srbds:                Not affected<br />
Vulnerability Tsx async abort:      Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.26.4<br />
[pip3] pytorch-triton==3.0.0+901819d2b6<br />
[pip3] torch==2.3.0.dev20240301+cu121<br />
[pip3] torchaudio==2.2.0.dev20240301+cu118<br />
[pip3] torchvision==0.18.0.dev20240301+cu118<br />
[pip3] triton==2.2.0<br />
[conda] numpy                     1.26.4                   pypi_0    pypi<br />
[conda] pytorch-triton            3.0.0+901819d2b6          pypi_0    pypi<br />
[conda] torch                     2.3.0.dev20240301+cu121          pypi_0    pypi<br />
[conda] torchaudio                2.2.0.dev20240301+cu118          pypi_0    pypi<br />
[conda] torchvision               0.18.0.dev20240301+cu118          pypi_0    pypi<br />
[conda] triton                    2.2.0                    pypi_0    pypi<br />
```</p>
<p>cc @ezyang @gchanan @zou3519 @kadeng @msaroufim @bdhirsh @anijain2305 @chauhang</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 20:22:33 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122382</guid>
    </item>
    <item>
      <title>[torch.compile] A potential OOB access in CUDA for attention model</title>
      <link>https://github.com/pytorch/pytorch/issues/122381</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>For the following model, the result optimized by <code>torch.compile</code> on CUDA is totally wrong, which may out-of-bound access some data.</p>
<p>```py<br />
import torch</p>
<p>torch.manual_seed(420)</p>
<p>class Model(torch.nn.Module):</p>
<pre><code>def __init__(self, d_model, dropout_p=0.1, inv_scale_factor=1e-08):
    super().__init__()
    self.d_model = d_model
    self.dropout_p = dropout_p
    self.inv_scale_factor = inv_scale_factor
    self.dropout = torch.nn.Dropout(dropout_p)

def forward(self, query, key, value):
    qk = torch.matmul(query, key.transpose(-2, -1))
    scaled_qk = qk.div(self.inv_scale_factor)
    softmax_qk = scaled_qk.softmax(dim=-1)
    dropout_qk = self.dropout(softmax_qk)
    return dropout_qk
</code></pre>
<p>device = "cuda"<br />
d_model = 1<br />
func = Model(10).to(device)</p>
<p>query = torch.randn(1, 5, 10).to(device)</p>
<p>key = torch.randn(1, 5, 10).to(device)</p>
<p>value = torch.randn(1, 5, 10).to(device)</p>
<p>with torch.no_grad():<br />
    naive_result = func(query.clone(), key.clone(), value.clone())</p>
<pre><code>func1 = torch.compile(func)
jit_result = func1(query.clone(), key.clone(), value.clone())

print(naive_result)
print(jit_result)
print(torch._dynamo.utils.counters["inductor"])
</code></pre>
<p>"""<br />
tensor([[[0.0000, 0.0000, 0.0000, 1.1111, 0.0000],<br />
         [0.0000, 0.0000, 1.1111, 0.0000, 0.0000],<br />
         [0.0000, 0.0000, 0.0000, 0.0000, 1.1111],<br />
         [0.0000, 0.0000, 0.0000, 1.1111, 0.0000],<br />
         [0.0000, 0.0000, 1.1111, 0.0000, 0.0000]]], device='cuda:0')<br />
tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],<br />
         [0.0000e+00, 0.0000e+00, 1.6732e+03, 0.0000e+00, 0.0000e+00],<br />
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0731e-10],<br />
         [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4720e-03, 0.0000e+00],<br />
         [0.0000e+00, 0.0000e+00, 4.0205e+06, 0.0000e+00, 0.0000e+00]]],<br />
       device='cuda:0')<br />
Counter({'pattern_matcher_count': 4, 'pattern_matcher_nodes': 4})<br />
"""<br />
```</p>
<p>This model has been minimized; therefore, if any operator is removed, it won't trigger the bug. Additionally, I've printed the patterns optimized by the Inductor to assist with debugging.</p>
<p><code>view (sum_1, [4]) Match(..., [], {'arg': sum_1, 'size': [4]}) CallFunction(aten.view.default, KeywordArg('arg'), KeywordArg('size'))
view_2 (None, [1, 5, 5]) Match(..., [], {'arg': bmm, 'size': [1, 5, 5]}) CallFunction(aten.view.default, KeywordArg('arg'), KeywordArg('size'))
view_1 (None, [1, 10, 5]) Match(..., [], {'arg': expand_1, 'size': [1, 10, 5]}) CallFunction(aten.view.default, KeywordArg('arg'), KeywordArg('size'))
view (None, [1, 5, 10]) Match(..., [], {'arg': expand, 'size': [1, 5, 10]}) CallFunction(aten.view.default, KeywordArg('arg'), KeywordArg('size'))
rand ([1, 5, 5],) Match(..., [[1, 5, 5]], {'dtype': torch.float32, 'device': device(type='cuda', index=0), 'pin_memory': False}) CallFunctionVarArgs(aten.rand.default)</code></p>
<p>It seems that this is <strong>not</strong> related to the <code>fuse_attention</code> optimization</p>
<h3>Versions</h3>
<p>```<br />
Collecting environment information...<br />
PyTorch version: 2.3.0.dev20240301+cu121<br />
Is debug build: False<br />
CUDA used to build PyTorch: 12.1<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.1 LTS (x86_64)<br />
GCC version: (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0<br />
Clang version: 11.0.0 (https://github.com/aflgo/aflgo.git fa125da5d70621daf7141c6279877c97708c8c1f)<br />
CMake version: version 3.22.1<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.9.0 (default, Nov 15 2020, 14:28:56)  [GCC 7.3.0] (64-bit runtime)<br />
Python platform: Linux-6.5.0-26-generic-x86_64-with-glibc2.35<br />
Is CUDA available: True<br />
CUDA runtime version: Could not collect<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3060<br />
Nvidia driver version: 525.147.05<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                       x86_64<br />
CPU op-mode(s):                     32-bit, 64-bit<br />
Address sizes:                      46 bits physical, 48 bits virtual<br />
Byte Order:                         Little Endian<br />
CPU(s):                             24<br />
On-line CPU(s) list:                0-23<br />
Vendor ID:                          GenuineIntel<br />
Model name:                         12th Gen Intel(R) Core(TM) i9-12900K<br />
CPU family:                         6<br />
Model:                              151<br />
Thread(s) per core:                 2<br />
Core(s) per socket:                 16<br />
Socket(s):                          1<br />
Stepping:                           2<br />
CPU max MHz:                        5200.0000<br />
CPU min MHz:                        800.0000<br />
BogoMIPS:                           6374.40<br />
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault cat_l2 cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect avx_vnni dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq tme rdpid movdiri movdir64b fsrm md_clear serialize pconfig arch_lbr ibt flush_l1d arch_capabilities<br />
Virtualization:                     VT-x<br />
L1d cache:                          640 KiB (16 instances)<br />
L1i cache:                          768 KiB (16 instances)<br />
L2 cache:                           14 MiB (10 instances)<br />
L3 cache:                           30 MiB (1 instance)<br />
NUMA node(s):                       1<br />
NUMA node0 CPU(s):                  0-23<br />
Vulnerability Gather data sampling: Not affected<br />
Vulnerability Itlb multihit:        Not affected<br />
Vulnerability L1tf:                 Not affected<br />
Vulnerability Mds:                  Not affected<br />
Vulnerability Meltdown:             Not affected<br />
Vulnerability Mmio stale data:      Not affected<br />
Vulnerability Retbleed:             Not affected<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl<br />
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:           Mitigation; Enhanced / Automatic IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence<br />
Vulnerability Srbds:                Not affected<br />
Vulnerability Tsx async abort:      Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.26.4<br />
[pip3] pytorch-triton==3.0.0+901819d2b6<br />
[pip3] torch==2.3.0.dev20240301+cu121<br />
[pip3] torchaudio==2.2.0.dev20240301+cu118<br />
[pip3] torchvision==0.18.0.dev20240301+cu118<br />
[pip3] triton==2.2.0<br />
[conda] numpy                     1.26.4                   pypi_0    pypi<br />
[conda] pytorch-triton            3.0.0+901819d2b6          pypi_0    pypi<br />
[conda] torch                     2.3.0.dev20240301+cu121          pypi_0    pypi<br />
[conda] torchaudio                2.2.0.dev20240301+cu118          pypi_0    pypi<br />
[conda] torchvision               0.18.0.dev20240301+cu118          pypi_0    pypi<br />
[conda] triton                    2.2.0                    pypi_0    pypi</p>
<p>```</p>
<p>cc @ezyang @gchanan @zou3519 @kadeng @msaroufim @bdhirsh @anijain2305 @chauhang @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 20:09:23 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122381</guid>
    </item>
    <item>
      <title>[torch.compile] `UnbindCatRemover` returns `KeyError: 'dim'` in `get_transform_params`</title>
      <link>https://github.com/pytorch/pytorch/issues/122380</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>The following model triggers  <code>KeyError: 'dim'</code> in <code>get_transform_params</code>, which is under <code>UnbindCatRemover</code>. Here is the link: https://github.com/pytorch/pytorch/blob/3e6fdea3900ce33d973893d00619b9bbe6bf8168/torch/_inductor/fx_passes/split_cat.py#L932</p>
<p>```<br />
import torch</p>
<p>torch.manual_seed(0)</p>
<p>class Model(torch.nn.Module):</p>
<pre><code>def __init__(self):
    super(Model, self).__init__()

def forward(self, x):
    t1 = torch.unbind(x)
    t2 = torch.stack(t1, dim=1)
    t3 = torch.tanh(t2)
    return t3
</code></pre>
<p>func = Model().to('cpu')</p>
<p>x = torch.randn(2, 3, 4)</p>
<p>with torch.no_grad():<br />
    func1 = torch.compile(func)<br />
    print(func1(x.clone()).shape)<br />
    """<br />
    File "torch/_inductor/fx_passes/split_cat.py", line 1085, in merge_unbind_stack<br />
    UnbindCatRemover().remove_unbind(match.graph, unbind_node)<br />
    File "torch/_inductor/fx_passes/split_cat.py", line 890, in remove_unbind<br />
        super().simplify(graph, unbind_node, split_sections)<br />
    File "torch/_inductor/fx_passes/split_cat.py", line 500, in simplify<br />
        transform_params_list = self.get_transform_params(<br />
    File "torch/_inductor/fx_passes/split_cat.py", line 932, in get_transform_params<br />
        split_dim = unbind_node.kwargs["dim"]<br />
    torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:<br />
    KeyError: 'dim'<br />
    """<br />
```</p>
<p>Run the model with <code>TORCHINDUCTOR_FREEZING=1 TORCHINDUCTOR_PERMUTE_FUSION=1 python test.py</code></p>
<h3>Versions</h3>
<p>```<br />
Versions<br />
PyTorch version: 2.3.0.dev20240301+cu118<br />
Is debug build: False<br />
CUDA used to build PyTorch: 11.8<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.1 LTS (x86_64)<br />
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br />
Clang version: 14.0.0-1ubuntu1.1<br />
CMake version: version 3.22.1<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.9.0 (default, Nov 15 2020, 14:28:56) [GCC 7.3.0] (64-bit runtime)<br />
Python platform: Linux-6.5.0-21-generic-x86_64-with-glibc2.35<br />
Is CUDA available: False<br />
CUDA runtime version: 11.5.119<br />
CUDA_MODULE_LOADING set to: N/A<br />
GPU models and configuration: Could not collect<br />
Nvidia driver version: Could not collect<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture: x86_64<br />
CPU op-mode(s): 32-bit, 64-bit<br />
Address sizes: 46 bits physical, 48 bits virtual<br />
Byte Order: Little Endian<br />
CPU(s): 24<br />
On-line CPU(s) list: 0-23<br />
Vendor ID: GenuineIntel<br />
Model name: 12th Gen Intel(R) Core(TM) i9-12900K<br />
CPU family: 6<br />
Model: 151<br />
Thread(s) per core: 2<br />
Core(s) per socket: 16<br />
Socket(s): 1<br />
Stepping: 2<br />
CPU max MHz: 5200.0000<br />
CPU min MHz: 800.0000<br />
BogoMIPS: 6374.40<br />
Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault cat_l2 cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect avx_vnni dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq tme rdpid movdiri movdir64b fsrm md_clear serialize pconfig arch_lbr ibt flush_l1d arch_capabilities<br />
Virtualization: VT-x<br />
L1d cache: 640 KiB (16 instances)<br />
L1i cache: 768 KiB (16 instances)<br />
L2 cache: 14 MiB (10 instances)<br />
L3 cache: 30 MiB (1 instance)<br />
NUMA node(s): 1<br />
NUMA node0 CPU(s): 0-23<br />
Vulnerability Gather data sampling: Not affected<br />
Vulnerability Itlb multihit: Not affected<br />
Vulnerability L1tf: Not affected<br />
Vulnerability Mds: Not affected<br />
Vulnerability Meltdown: Not affected<br />
Vulnerability Mmio stale data: Not affected<br />
Vulnerability Retbleed: Not affected<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl<br />
Vulnerability Spectre v1: Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2: Mitigation; Enhanced / Automatic IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence<br />
Vulnerability Srbds: Not affected<br />
Vulnerability Tsx async abort: Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.26.4<br />
[pip3] pytorch-triton==3.0.0+901819d2b6<br />
[pip3] torch==2.3.0.dev20240301+cu118<br />
[pip3] torchaudio==2.2.0.dev20240301+cu118<br />
[pip3] torchvision==0.18.0.dev20240301+cu118<br />
[conda] numpy 1.26.4 pypi_0 pypi<br />
[conda] pytorch-triton 3.0.0+901819d2b6 pypi_0 pypi<br />
[conda] torch 2.3.0.dev20240301+cu118 pypi_0 pypi<br />
[conda] torchaudio 2.2.0.dev20240301+cu118 pypi_0 pypi<br />
[conda] torchvision 0.18.0.dev20240301+cu118 pypi_0 pypi<br />
```</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 19:29:42 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122380</guid>
    </item>
    <item>
      <title>[torch.compile] `split_cat_norm` and `cat_mutated` cause the optimized model to return a tensor with wrong shape</title>
      <link>https://github.com/pytorch/pytorch/issues/122379</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>The following model should return a tensor with shape <code>[10, 3, 64, 64]</code>, however, it seems that <code>split_cat_norm</code> and <code>cat_mutated</code> cause the optimized model to return a tensor with wrong shape, which is <code>[2, 3, 64, 64]</code></p>
<p>```py<br />
import torch</p>
<p>torch.manual_seed(0)</p>
<p>class Model(torch.nn.Module):</p>
<pre><code>def __init__(self):
    super().__init__()
    self.conv = torch.nn.Conv2d(3, 8, 1, stride=1, padding=1)
    self.indices = [i for i in range(0, 10)]

def forward(self, x):
    split_tensors = torch.split(x, 1, 0) # len(split_tensors) == 10
    chosen_tensors = [split_tensors[i] for i in self.indices if i in range(0, 10)]
    result = torch.cat(chosen_tensors, 0)
    return result
</code></pre>
<p>func = Model().to('cpu')</p>
<p>x = torch.randn(10, 3, 64, 64)</p>
<p>with torch.no_grad():<br />
    func1 = torch.compile(func)<br />
    print(func1(x.clone()).shape)<br />
    # torch.Size([2, 3, 64, 64])<br />
    print(torch._dynamo.utils.counters['inductor'])<br />
    # Counter({'pattern_matcher_nodes': 11, 'pattern_matcher_count': 5, 'split_cat_norm': 2, 'cat_mutated': 1})</p>
<pre><code>print(func(x.clone()).shape)
# torch.Size([10, 3, 64, 64])
</code></pre>
<p>```</p>
<h3>Versions</h3>
<p>```<br />
Versions<br />
PyTorch version: 2.3.0.dev20240301+cu118<br />
Is debug build: False<br />
CUDA used to build PyTorch: 11.8<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.1 LTS (x86_64)<br />
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br />
Clang version: 14.0.0-1ubuntu1.1<br />
CMake version: version 3.22.1<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.9.0 (default, Nov 15 2020, 14:28:56) [GCC 7.3.0] (64-bit runtime)<br />
Python platform: Linux-6.5.0-21-generic-x86_64-with-glibc2.35<br />
Is CUDA available: False<br />
CUDA runtime version: 11.5.119<br />
CUDA_MODULE_LOADING set to: N/A<br />
GPU models and configuration: Could not collect<br />
Nvidia driver version: Could not collect<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture: x86_64<br />
CPU op-mode(s): 32-bit, 64-bit<br />
Address sizes: 46 bits physical, 48 bits virtual<br />
Byte Order: Little Endian<br />
CPU(s): 24<br />
On-line CPU(s) list: 0-23<br />
Vendor ID: GenuineIntel<br />
Model name: 12th Gen Intel(R) Core(TM) i9-12900K<br />
CPU family: 6<br />
Model: 151<br />
Thread(s) per core: 2<br />
Core(s) per socket: 16<br />
Socket(s): 1<br />
Stepping: 2<br />
CPU max MHz: 5200.0000<br />
CPU min MHz: 800.0000<br />
BogoMIPS: 6374.40<br />
Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault cat_l2 cdp_l2 ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdt_a rdseed adx smap clflushopt clwb intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves split_lock_detect avx_vnni dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp hwp_pkg_req hfi vnmi umip pku ospke waitpkg gfni vaes vpclmulqdq tme rdpid movdiri movdir64b fsrm md_clear serialize pconfig arch_lbr ibt flush_l1d arch_capabilities<br />
Virtualization: VT-x<br />
L1d cache: 640 KiB (16 instances)<br />
L1i cache: 768 KiB (16 instances)<br />
L2 cache: 14 MiB (10 instances)<br />
L3 cache: 30 MiB (1 instance)<br />
NUMA node(s): 1<br />
NUMA node0 CPU(s): 0-23<br />
Vulnerability Gather data sampling: Not affected<br />
Vulnerability Itlb multihit: Not affected<br />
Vulnerability L1tf: Not affected<br />
Vulnerability Mds: Not affected<br />
Vulnerability Meltdown: Not affected<br />
Vulnerability Mmio stale data: Not affected<br />
Vulnerability Retbleed: Not affected<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl<br />
Vulnerability Spectre v1: Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2: Mitigation; Enhanced / Automatic IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence<br />
Vulnerability Srbds: Not affected<br />
Vulnerability Tsx async abort: Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.26.4<br />
[pip3] pytorch-triton==3.0.0+901819d2b6<br />
[pip3] torch==2.3.0.dev20240301+cu118<br />
[pip3] torchaudio==2.2.0.dev20240301+cu118<br />
[pip3] torchvision==0.18.0.dev20240301+cu118<br />
[conda] numpy 1.26.4 pypi_0 pypi<br />
[conda] pytorch-triton 3.0.0+901819d2b6 pypi_0 pypi<br />
[conda] torch 2.3.0.dev20240301+cu118 pypi_0 pypi<br />
[conda] torchaudio 2.2.0.dev20240301+cu118 pypi_0 pypi<br />
[conda] torchvision 0.18.0.dev20240301+cu118 pypi_0 pypi<br />
```</p>
<p>cc @ezyang @gchanan @zou3519 @kadeng @msaroufim @bdhirsh @anijain2305 @chauhang</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 19:19:37 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/122379</guid>
    </item>
    <item>
      <title>[Quant] [Inductor] Enable the Inductor Lowering of QConv2d post op HardTanh with int8-mix-bf16</title>
      <link>https://github.com/pytorch/pytorch/pull/122374</link>
      <description><![CDATA[<p><strong>Summary</strong><br />
Enable the fusion pattern of <code>QConv2d -&gt; hardtanh</code> lowering for int8-mixed-bf16 case.</p>
<p><strong>Test Plan</strong><br />
<code>python -m pytest test_mkldnn_pattern_matcher.py -k test_qconv2d_hardtanh_int8_mixed_bf16_cpu</code></p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122374<br />
* #122373<br />
* #122268<br />
* #122267<br />
* #122266</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 19:02:16 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122374</guid>
    </item>
    <item>
      <title>[Quant] [Inductor] Enable the Inductor Lowering of QConv2d post op HardSwish with int8-mix-bf16</title>
      <link>https://github.com/pytorch/pytorch/pull/122373</link>
      <description><![CDATA[<p><strong>Summary</strong><br />
Enable the fusion pattern of <code>QConv2d -&gt; hardswish</code> lowering for int8-mixed-bf16 case.</p>
<p><strong>Test Plan</strong><br />
<code>python -m pytest test_mkldnn_pattern_matcher.py -k test_qconv2d_hardswish_int8_mixed_bf16_cpu</code></p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122374<br />
* <strong>-&gt;</strong> #122373<br />
* #122268<br />
* #122267<br />
* #122266</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 19:02:11 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122373</guid>
    </item>
    <item>
      <title>[effects] Add inductor support for tokens</title>
      <link>https://github.com/pytorch/pytorch/pull/122347</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122348<br />
* <strong>-&gt;</strong> #122347<br />
* #122346</p>
<p>This is done by adding a lowering for <code>with_effects</code> which converts the operator call to an <code>EffectfulKernel</code>. This is basically just a <code>FallbackKernel</code> but with a pointer to previous effectful operator's call. During scheduling, we will create a <code>StarDep</code> between these two calls so that they don't get reordered.</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Wed, 20 Mar 2024 14:10:17 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122347</guid>
    </item>
    <item>
      <title>[Quant] [Inductor] Enable the Inductor Lowering of QConv2d post op SiLU</title>
      <link>https://github.com/pytorch/pytorch/pull/122268</link>
      <description><![CDATA[<p><strong>Summary</strong><br />
Enable the fusion pattern of <code>QConv2d -&gt; silu</code> lowering to <code>swish</code> as <code>QConv2d</code> post operator. </p>
<p><strong>Test Plan</strong><br />
<code>python -m pytest test_mkldnn_pattern_matcher.py -k test_qconv2d_silu_cpu
python -m pytest test_mkldnn_pattern_matcher.py -k test_qconv2d_silu_int8_mixed_bf16_cpu
python -m pytest test_mkldnn_pattern_matcher.py -k test_qat_qconv2d_silu</code></p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122374<br />
* #122373<br />
* <strong>-&gt;</strong> #122268<br />
* #122267<br />
* #122266</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 19 Mar 2024 18:53:41 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122268</guid>
    </item>
    <item>
      <title>[Quant] [PT2] Add SiLU  into X86InductorQuantizer Conv2d Unary Annotation</title>
      <link>https://github.com/pytorch/pytorch/pull/122267</link>
      <description><![CDATA[<p><strong>Summary</strong><br />
Add <code>SiLU</code> into X86InductorQuantizer Conv2d Unary Annotation</p>
<p><strong>TestPlan</strong><br />
<code>python -m pytest test_x86inductor_quantizer.py -k test_conv2d_unary
python -m pytest test_x86inductor_quantizer.py -k test_qat_conv2d_unary</code></p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122374<br />
* #122373<br />
* #122268<br />
* <strong>-&gt;</strong> #122267<br />
* #122266</p>]]></description>
      <pubDate>Tue, 19 Mar 2024 18:53:35 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122267</guid>
    </item>
    <item>
      <title>Use graph.find_nodes in inductor</title>
      <link>https://github.com/pytorch/pytorch/pull/122256</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122331<br />
* #122258<br />
* #122257<br />
* <strong>-&gt;</strong> #122256<br />
* #122255<br />
* #121565<br />
* #122330</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 19 Mar 2024 17:27:14 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122256</guid>
    </item>
    <item>
      <title>Use graph.find_nodes in inductor/fx_passes</title>
      <link>https://github.com/pytorch/pytorch/pull/122255</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122331<br />
* #122258<br />
* #122257<br />
* #122256<br />
* <strong>-&gt;</strong> #122255<br />
* #121565<br />
* #122330</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 19 Mar 2024 17:27:08 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122255</guid>
    </item>
    <item>
      <title>[Reland][Inductor] Add support for NEON ISA For Mac OS</title>
      <link>https://github.com/pytorch/pytorch/pull/122217</link>
      <description><![CDATA[<p>This is a re-land of https://github.com/pytorch/pytorch/pull/105590 but this time enbaling it only for Darwin platform where those instructions are available by default.</p>
<p>See table below for perf gains with and without torch.compile using <a href="https://github.com/pytorch-labs/gpt-fast">gpt-fast</a> running <code>stories15M</code> on M2 Pro:<br />
| dtype  | Eager | Compile |<br />
| ------ | ------ | --------- |<br />
| bfloat16  | 120 tokens/sec  | 156 tokens/sec |<br />
| float32  | 158 tokens/sec  | 236 tokens/sec |<br />
| float16  | 235 tokens/sec  | 58 tokens/sec |</p>
<p>cc @jgong5 @mingfeima @XiaobingSuper @sanchitintel @ashokei @jingxu10 @voznesenskym @penguinwu @EikanWang @Guobing-Chen @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Tue, 19 Mar 2024 10:42:00 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122217</guid>
    </item>
    <item>
      <title>[inductor] config to control whether we assume inputs are aligned</title>
      <link>https://github.com/pytorch/pytorch/pull/122158</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #122158</p>
<p><strong>Motivation</strong>: https://github.com/pytorch/pytorch/issues/112771</p>
<p><strong>Summary</strong>: Inductor generates triton that assumes that inputs are going to be 16-byte aligned. If the inputs aren't aligned, Inductor clones the inputs. This PR introduces a config option to not do this: when assume_aligned_inputs=False, Inductor will <em>not</em> pass inputs as being divisible_by_16, and Inductor will not make clones. This an can generate code that might be a bit slower, but this tradeoff can be worth it in some scenarios where you might otherwise make a lot of clones.</p>
<p>Ideally, we could do this on a per-tensor basis. But this would be a lot of work, and attempts to add guards on storage offsets to do this automatically have run into issues: recompilations and excessive time to generate/check guards.</p>
<p><strong>Tests</strong> https://github.com/pytorch/pytorch/pull/122159 flips this to False. It didn't run through all errors, but the ones we see are all expected failures: divisible_by_16 changes; triton kernel caching fails if we call the same triton kernel multiple times (this makes sense because the first call will have unaligned inputs, but subsequent calls have aligned inputs); and some xfailed tests start passing.</p>
<p><strong>Alternatives/RFC</strong>:<br />
* Is this the right thing to do with cudagraphs?<br />
* Elias and Jason mentioned that we probably still want to make clones if we're dealing with unaligned inputs to matmuls. Is this something we should add in this config option? (In the use case I'm targeting, it seems like we don't need this optimization right now)</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>
<p>Differential Revision: <a href="https://our.internmc.facebook.com/intern/diff/D55079094">D55079094</a></p>]]></description>
      <pubDate>Mon, 18 Mar 2024 16:25:56 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/122158</guid>
    </item>
    <item>
      <title>Precompile triton templates</title>
      <link>https://github.com/pytorch/pytorch/pull/121998</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #121999<br />
* <strong>-&gt;</strong> #121998</p>
<p>Before this PR we were not precompiling triton templates in parallel. Compilation would occur during benchmarking.</p>
<p>Triton benchmarking templates were emitted as :</p>
<p><code>@triton.jit
def triton_mm(arg_A, arg_B, out_ptr0):</code></p>
<p>In order to precompile we need to give the full kernel specification, as we do when we emit the template in the final output code generation.</p>
<p><code>@triton_heuristics.template(
    num_stages=3,
    num_warps=8,
    triton_meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
    inductor_meta={'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'backend_hash': 'cdeecfeccd31ad7810f96b5752194b1c2406d0a81e39a6ca09c8ee150baae183'},
)
@triton.jit
def triton_mm(arg_A, arg_B, out_ptr0):</code></p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Fri, 15 Mar 2024 13:46:18 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/121998</guid>
    </item>
    <item>
      <title>[RFC] Use CUDA graphs by default on torch.compile</title>
      <link>https://github.com/pytorch/pytorch/issues/121968</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>I keep seeing comparisons between JAX / TF / Keras vs <code>torch.compile</code> where they benchmark the "default XLA settings vs. the default <code>torch.compile</code>" to find that XLA frontends are x3-x4 faster than <code>torch.compile</code>.<br />
The last one I found is the newly posted Keras 3 benchmarks<br />
https://keras.io/getting_started/benchmarks/ <br />
but I have seen these skewed comparisons over and over again.</p>
<p>The only thing stopping us from compiling with CUDA graphs on is that these sometimes have a higher mem footprint. Would it be reasonable to turn these on by default so that people get speed by default, and then catch a potential OOM and re-raise it indicating that using CUDA-graphs off to potentialy mitigate the OOM?</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @jansel @albanD @eellison @Chillee </p>
<h3>Versions</h3>
<p>master</p>]]></description>
      <pubDate>Fri, 15 Mar 2024 05:32:36 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/121968</guid>
    </item>
    <item>
      <title>[inductor][cpp] move vectorized type conversion to aten/cpu/vec</title>
      <link>https://github.com/pytorch/pytorch/pull/119979</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #119979<br />
* #119734<br />
* #119655<br />
* #119654</p>
<p>cc @mingfeima @XiaobingSuper @sanchitintel @ashokei @jingxu10 @voznesenskym @penguinwu @EikanWang @Guobing-Chen @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler</p>]]></description>
      <pubDate>Wed, 14 Feb 2024 21:46:22 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/119979</guid>
    </item>
    <item>
      <title>[inductor][cpp] simplify CppVecKernelChecker (remove bool/int8 load as mask and load as float flags)</title>
      <link>https://github.com/pytorch/pytorch/pull/119734</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #119979<br />
* <strong>-&gt;</strong> #119734<br />
* #119655<br />
* #119654</p>
<p>cc @mingfeima @XiaobingSuper @sanchitintel @ashokei @jingxu10 @voznesenskym @penguinwu @EikanWang @Guobing-Chen @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler</p>]]></description>
      <pubDate>Mon, 12 Feb 2024 16:39:29 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/119734</guid>
    </item>
    <item>
      <title>[inductor] Remove identity from ops.scan</title>
      <link>https://github.com/pytorch/pytorch/pull/119727</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122137<br />
* #119430<br />
* <strong>-&gt;</strong> #119727<br />
* #122136</p>
<p>Currently scan has an <code>init</code> argument which must be the identity of the<br />
combine function. This isn't strictly necessary if we are more careful about<br />
keeping track of the first element and avoid combining it with anything.</p>
<p>This does additionally require that there are no active load masks, since we can't<br />
do the <code>where_cond</code> any more. However, this shouldn't be possible anyway since<br />
scans are always realized and only fused via the scheduler.</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler</p>]]></description>
      <pubDate>Mon, 12 Feb 2024 15:27:53 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/119727</guid>
    </item>
    <item>
      <title>[inductor][cpp] support vectorized indirect indexing</title>
      <link>https://github.com/pytorch/pytorch/pull/119655</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #119979<br />
* #119734<br />
* <strong>-&gt;</strong> #119655<br />
* #119654</p>
<p>cc @mingfeima @XiaobingSuper @sanchitintel @ashokei @jingxu10 @voznesenskym @penguinwu @EikanWang @Guobing-Chen @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler</p>]]></description>
      <pubDate>Sun, 11 Feb 2024 07:08:54 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/119655</guid>
    </item>
    <item>
      <title>[inductor][cpp] generalize vector mask for dtypes</title>
      <link>https://github.com/pytorch/pytorch/pull/119654</link>
      <description><![CDATA[<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #119979<br />
* #119734<br />
* #119655<br />
* <strong>-&gt;</strong> #119654</p>
<p>cc @mingfeima @XiaobingSuper @sanchitintel @ashokei @jingxu10 @voznesenskym @penguinwu @EikanWang @Guobing-Chen @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler</p>]]></description>
      <pubDate>Sun, 11 Feb 2024 07:08:46 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/119654</guid>
    </item>
    <item>
      <title>torch.compile changes the dtype of key matrix in attention implementation with torch.set_default_dtype</title>
      <link>https://github.com/pytorch/pytorch/issues/119162</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>Below is a minimal repro of an example where <code>torch.compile</code> uses different dtypes than eager for the computation, causing a type mismatch error:</p>
<p><code>Expected query, key, and value to have the same dtype, but got query.dtype: c10::BFloat16 key.dtype: float and value.dtype: float instead.</code></p>
<p>```py<br />
import torch.nn as nn<br />
import torch.nn.functional as F<br />
import torch</p>
<p>class VAE(nn.Module):<br />
    def <strong>init</strong>(self):<br />
        super().<strong>init</strong>()<br />
        self.tok_emb = nn.Embedding(128, embedding_dim=128)<br />
        self.cross_attn = MultiheadAttention(128, 8)</p>
<pre><code>def forward(self, tokens):
    embed = self.tok_emb(tokens)
    z = torch.randn(embed.shape[0], 4, embed.shape[2], device=embed.device, dtype=embed.dtype)
    logits = self.cross_attn(embed, z, z)
    return logits.mean()
</code></pre>
<p>class MultiheadAttention(nn.Module):<br />
    def <strong>init</strong>(self, embed_dim: int, heads: int):<br />
        super().<strong>init</strong>()</p>
<pre><code>    self.embed_size = embed_dim
    self.num_heads = heads
    self.head_dim = embed_dim // heads

    assert self.head_dim * heads == embed_dim, "Embedding size needs to be divisible by heads"

    self.q_proj = nn.Linear(self.embed_size, self.embed_size)
    self.k_proj = nn.Linear(self.embed_size, self.embed_size)
    self.v_proj = nn.Linear(self.embed_size, self.embed_size)

def forward(self, query, key, value):
    N = query.shape[0]

    q = query.view(N, -1, self.num_heads, self.head_dim).swapaxes(1, 2)
    k = key.view(N, -1, self.num_heads, self.head_dim).swapaxes(1, 2)
    v = value.view(N, -1, self.num_heads, self.head_dim).swapaxes(1, 2)

    # Without compile: torch.bfloat16 torch.bfloat16 torch.bfloat16
    # With compile:    torch.bfloat16 torch.float32 torch.float32
    print(q.dtype, k.dtype, v.dtype)

    attn = F.scaled_dot_product_attention(q, k, v)
    attn = attn.swapaxes(1, 2).reshape(N, -1, self.embed_size)
    return attn
</code></pre>
<p>model = VAE()<br />
model = VAE().to(device="cuda", dtype=torch.bfloat16)</p>
<h1>Without compile, this runs fine</h1>
<p>model = torch.compile(model)</p>
<p>input = torch.randint(0, 128, (512, 128), device=torch.device("cuda"))</p>
<p>torch.set_default_dtype(torch.bfloat16)  # &lt; -------- THIS LINE IS PROBLEMATIC?<br />
loss = model(input)<br />
loss.backward()</p>
<p>```</p>
<p>Error:</p>
<p>```<br />
Traceback (most recent call last):<br />
  File "/home/adrian/repositories/lightning/examples/pytorch/bug_report/bug_report_model.py", line 62, in <module><br />
    loss = model(input)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl<br />
    return self._call_impl(<em>args, </em><em>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl<br />
    return forward_call(</em>args, <strong>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 453, in _fn<br />
    return fn(*args, </strong>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl<br />
    return self._call_impl(<em>args, </em><em>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl<br />
    return forward_call(</em>args, <strong>kwargs)<br />
  File "/home/adrian/repositories/lightning/examples/pytorch/bug_report/bug_report_model.py", line 15, in forward<br />
    logits = self.cross_attn(embed, z, z)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl<br />
    return self._call_impl(*args, </strong>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl<br />
    return forward_call(<em>args, </em><em>kwargs)<br />
  File "/home/adrian/repositories/lightning/examples/pytorch/bug_report/bug_report_model.py", line 46, in forward<br />
    print(q.dtype, k.dtype, v.dtype)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 615, in catch_errors<br />
    return callback(frame, cache_entry, hooks, frame_state)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 748, in _convert_frame<br />
    result = inner_convert(frame, cache_entry, hooks, frame_state)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 390, in _convert_frame_assert<br />
    return _compile(<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/contextlib.py", line 79, in inner<br />
    return func(</em>args, <strong>kwds)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 650, in _compile<br />
    guarded_code = compile_inner(code, one_graph, hooks, transform)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 248, in time_wrapper<br />
    r = func(*args, </strong>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 531, in compile_inner<br />
    out_code = transform_code_object(code, transform)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object<br />
    transformations(instructions, code_options)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 155, in _fn<br />
    return fn(<em>args, </em><em>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 496, in transform<br />
    tracer.run()<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2125, in run<br />
    super().run()<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 787, in run<br />
    and self.step()<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 750, in step<br />
    getattr(self, inst.opname)(inst)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 469, in wrapper<br />
    return inner_fn(self, inst)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1196, in CALL_FUNCTION<br />
    self.call_function(fn, args, {})<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 651, in call_function<br />
    self.push(fn.call_function(self, args, kwargs))<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/variables/torch.py", line 614, in call_function<br />
    tensor_variable = wrap_fx_proxy(<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 1285, in wrap_fx_proxy<br />
    return wrap_fx_proxy_cls(target_cls=TensorVariable, </em><em>kwargs)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 1370, in wrap_fx_proxy_cls<br />
    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1653, in get_fake_value<br />
    raise TorchRuntimeError(str(e)).with_traceback(e.<strong>traceback</strong>) from None<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1599, in get_fake_value<br />
    ret_val = wrap_fake_exception(<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1140, in wrap_fake_exception<br />
    return fn()<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1600, in <lambda><br />
    lambda: run_node(tx.output, node, args, kwargs, nnmodule)<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1720, in run_node<br />
    raise RuntimeError(fn_str + str(e)).with_traceback(e.<strong>traceback</strong>) from e<br />
  File "/home/adrian/.conda/envs/lightning/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1699, in run_node<br />
    return node.target(</em>args, <strong>kwargs)<br />
torch._dynamo.exc.TorchRuntimeError: Failed running call_function <built-in function scaled_dot_product_attention>(*(FakeTensor(..., device='cuda:0', size=(512, 8, 128, 16),<br />
           grad_fn=<AsStridedBackward0>), FakeTensor(..., device='cuda:0', size=(512, 8, 4, 16), dtype=torch.float32), FakeTensor(..., device='cuda:0', size=(512, 8, 4, 16), dtype=torch.float32)), </strong>{}):<br />
Expected query, key, and value to have the same dtype, but got query.dtype: c10::BFloat16 key.dtype: float and value.dtype: float instead.</p>
<p>from user code:<br />
   File "/home/adrian/repositories/lightning/examples/pytorch/bug_report/bug_report_model.py", line 48, in torch_dynamo_resume_in_forward_at_46<br />
    attn = F.scaled_dot_product_attention(q, k, v)</p>
<p>Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information</p>
<p>You can suppress this exception and fall back to eager by setting:<br />
    import torch._dynamo<br />
    torch._dynamo.config.suppress_errors = True<br />
```</p>
<p>This is unexpected because the code runs fine without <code>torch.compile</code> applied. It looks like <code>torch.compile</code> can't handle this line properly:</p>
<p><code>py
torch.set_default_dtype(torch.bfloat16)</code></p>
<h3>Versions</h3>
<p>Collecting environment information...<br />
PyTorch version: 2.3.0.dev20240201+cu121<br />
Is debug build: False<br />
CUDA used to build PyTorch: 12.1<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 22.04.3 LTS (x86_64)<br />
GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br />
Clang version: Could not collect<br />
CMake version: version 3.26.0<br />
Libc version: glibc-2.35</p>
<p>Python version: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0] (64-bit runtime)<br />
Python platform: Linux-5.15.0-75-generic-x86_64-with-glibc2.35<br />
Is CUDA available: True<br />
CUDA runtime version: Could not collect<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: <br />
GPU 0: NVIDIA A100-SXM4-40GB<br />
GPU 1: NVIDIA A100-SXM4-40GB<br />
GPU 2: NVIDIA A100-SXM4-40GB<br />
GPU 3: NVIDIA A100-SXM4-40GB<br />
GPU 4: NVIDIA A100-SXM4-40GB<br />
GPU 5: NVIDIA A100-SXM4-40GB<br />
GPU 6: NVIDIA A100-SXM4-40GB<br />
GPU 7: NVIDIA A100-SXM4-40GB</p>
<p>Nvidia driver version: 525.125.06<br />
cuDNN version: Probably one of the following:<br />
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.5<br />
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.5<br />
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.5<br />
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.5<br />
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.5<br />
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.5<br />
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.5<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                    x86_64<br />
CPU op-mode(s):                  32-bit, 64-bit<br />
Address sizes:                   43 bits physical, 48 bits virtual<br />
Byte Order:                      Little Endian<br />
CPU(s):                          256<br />
On-line CPU(s) list:             0-254<br />
Off-line CPU(s) list:            255<br />
Vendor ID:                       AuthenticAMD<br />
Model name:                      AMD EPYC 7742 64-Core Processor<br />
CPU family:                      23<br />
Model:                           49<br />
Thread(s) per core:              2<br />
Core(s) per socket:              64<br />
Socket(s):                       2<br />
Stepping:                        0<br />
Frequency boost:                 enabled<br />
CPU max MHz:                     2250.0000<br />
CPU min MHz:                     0.0000<br />
BogoMIPS:                        4499.83<br />
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sme sev sev_es<br />
Virtualization:                  AMD-V<br />
L1d cache:                       4 MiB (128 instances)<br />
L1i cache:                       4 MiB (128 instances)<br />
L2 cache:                        64 MiB (128 instances)<br />
L3 cache:                        512 MiB (32 instances)<br />
NUMA node(s):                    2<br />
NUMA node0 CPU(s):               0-63,128-191<br />
NUMA node1 CPU(s):               64-127,192-254<br />
Vulnerability Itlb multihit:     Not affected<br />
Vulnerability L1tf:              Not affected<br />
Vulnerability Mds:               Not affected<br />
Vulnerability Meltdown:          Not affected<br />
Vulnerability Mmio stale data:   Not affected<br />
Vulnerability Retbleed:          Mitigation; untrained return thunk; SMT enabled with STIBP protection<br />
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp<br />
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected<br />
Vulnerability Srbds:             Not affected<br />
Vulnerability Tsx async abort:   Not affected</p>
<p>Versions of relevant libraries:<br />
[pip3] mypy==1.4.1<br />
[pip3] mypy-extensions==1.0.0<br />
[pip3] numpy==1.24.2<br />
[pip3] onnx==1.12.0<br />
[pip3] onnxruntime==1.14.1<br />
[pip3] pytorch-lightning==2.0.6<br />
[pip3] pytorch-triton==3.0.0+901819d2b6<br />
[pip3] torch==2.3.0.dev20240201+cu121<br />
[pip3] torch-tb-profiler==0.4.3<br />
[pip3] torchmetrics==1.3.0.post0<br />
[pip3] torchvision==0.17.0<br />
[pip3] triton==2.2.0<br />
[conda] numpy                     1.24.2                   pypi_0    pypi<br />
[conda] pytorch-lightning         2.0.6                    pypi_0    pypi<br />
[conda] pytorch-triton            3.0.0+901819d2b6          pypi_0    pypi<br />
[conda] torch                     2.3.0.dev20240201+cu121          pypi_0    pypi<br />
[conda] torch-tb-profiler         0.4.3                    pypi_0    pypi<br />
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi<br />
[conda] torchvision               0.17.0                   pypi_0    pypi<br />
[conda] triton                    2.2.0                    pypi_0    pypi</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang</p>]]></description>
      <pubDate>Sun, 04 Feb 2024 19:55:34 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/119162</guid>
    </item>
    <item>
      <title>inductor: fix for functional_collectives.wait() followed by view()</title>
      <link>https://github.com/pytorch/pytorch/pull/118802</link>
      <description><![CDATA[<p>Potential fix for https://github.com/pytorch/pytorch/issues/118759. See the issue linked for more diagnosis / explanation of this (tentative) fix. Feedback welcome!</p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* #122502<br />
* <strong>-&gt;</strong> #118802<br />
* #118670</p>
<p>cc @mrshenli @pritamdamania87 @zhaojuanmao @satgera @rohan-varma @gqchen @aazzolini @osalpekar @jiayisuse @H-Huang @kwen2501 @awgu @penguinwu @fegin @XilunWu @wanchaol @fduwjj @wz337 @tianyu-l @wconstab @yf225 @chauhang @voznesenskym @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire</p>]]></description>
      <pubDate>Wed, 31 Jan 2024 13:37:43 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/118802</guid>
    </item>
    <item>
      <title>Getting "RuntimeError: Trying to backward through the graph a second time" when calling backward on compiled unbind / split ops</title>
      <link>https://github.com/pytorch/pytorch/issues/118739</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>Since Pytorch 2.2 (until now - current PT nightly) trying to run backward() on compiled unbind or split ops, a RuntimeError is thrown. As suggested in the error message, calling backward() with retain_graph=True prevents the error from occuring. However previous PT versions (2.1) did not require that to work. <br />
Is this an expected bahaviour or a new bug that a workaround with retain_graph=True hides?</p>
<h3>Error logs</h3>
<p>‚ûú  ~ python3 unbind_repro.py<br />
Traceback (most recent call last):<br />
  File "/home/ubu/unbind_repro.py", line 14, in <module><br />
    i.backward() #retain_graph=True)<br />
    ^^^^^^^^^^^^<br />
  File "/home/ubu/.local/lib/python3.11/site-packages/torch/_tensor.py", line 524, in backward<br />
    torch.autograd.backward(<br />
  File "/home/ubu/.local/lib/python3.11/site-packages/torch/autograd/<strong>init</strong>.py", line 267, in backward<br />
    _engine_run_backward(<br />
  File "/home/ubu/.local/lib/python3.11/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward<br />
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass<br />
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/ubu/.local/lib/python3.11/site-packages/torch/autograd/function.py", line 294, in apply<br />
    return user_fn(self, <em>args)<br />
           ^^^^^^^^^^^^^^^^^^^^<br />
  File "/home/ubu/.local/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 620, in backward<br />
</em>ctx.saved_tensors,<br />
     ^^^^^^^^^^^^^^^^^<br />
RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.</p>
<h3>Minified repro</h3>
<p>```<br />
import torch</p>
<p>input = torch.Tensor([1, 2, 3, 4, 8])<br />
input.requires_grad = True</p>
<p>def foo(input):<br />
  outputs = torch.unbind(input, 0)<br />
  return outputs</p>
<p>fooCompiled = torch.compile(foo)<br />
out = fooCompiled(input)</p>
<p>for i in out:<br />
  i.backward() #retain_graph=True)</p>
<p>print(out)<br />
```</p>
<h3>Versions</h3>
<p>PyTorch version: 2.3.0.dev20240129+cpu<br />
Is debug build: False<br />
CUDA used to build PyTorch: Could not collect<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 23.04 (x86_64)<br />
GCC version: (Ubuntu 12.3.0-1ubuntu1~23.04) 12.3.0<br />
Clang version: 15.0.7<br />
CMake version: version 3.25.1<br />
Libc version: glibc-2.37</p>
<p>Python version: 3.11.4 (main, Dec  7 2023, 15:43:41) [GCC 12.3.0] (64-bit runtime)<br />
Python platform: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.37<br />
Is CUDA available: False<br />
CUDA runtime version: 11.8.89<br />
CUDA_MODULE_LOADING set to: N/A<br />
GPU models and configuration: Could not collect<br />
Nvidia driver version: Could not collect<br />
cuDNN version: Could not collect<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                       x86_64<br />
CPU op-mode(s):                     32-bit, 64-bit<br />
Address sizes:                      39 bits physical, 48 bits virtual<br />
Byte Order:                         Little Endian<br />
CPU(s):                             8<br />
On-line CPU(s) list:                0-7<br />
Vendor ID:                          GenuineIntel<br />
Model name:                         Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz<br />
CPU family:                         6<br />
Model:                              142<br />
Thread(s) per core:                 2<br />
Core(s) per socket:                 4<br />
Socket(s):                          1<br />
Stepping:                           12<br />
BogoMIPS:                           4224.01<br />
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pdcm pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi ept vpid ept_ad fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves flush_l1d arch_capabilities<br />
Virtualization:                     VT-x<br />
Hypervisor vendor:                  Microsoft<br />
Virtualization type:                full<br />
L1d cache:                          128 KiB (4 instances)<br />
L1i cache:                          128 KiB (4 instances)<br />
L2 cache:                           1 MiB (4 instances)<br />
L3 cache:                           8 MiB (1 instance)<br />
Vulnerability Gather data sampling: Unknown: Dependent on hypervisor status<br />
Vulnerability Itlb multihit:        KVM: Mitigation: VMX disabled<br />
Vulnerability L1tf:                 Not affected<br />
Vulnerability Mds:                  Not affected<br />
Vulnerability Meltdown:             Not affected<br />
Vulnerability Mmio stale data:      Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown<br />
Vulnerability Retbleed:             Mitigation; Enhanced IBRS<br />
Vulnerability Spec rstack overflow: Not affected<br />
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp<br />
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization<br />
Vulnerability Spectre v2:           Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence<br />
Vulnerability Srbds:                Unknown: Dependent on hypervisor status<br />
Vulnerability Tsx async abort:      Mitigation; TSX disabled</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.24.2<br />
[pip3] torch==2.3.0.dev20240129+cpu<br />
[pip3] torchaudio==2.2.0.dev20240129+cpu<br />
[pip3] torchvision==0.18.0.dev20240129+cpu<br />
[conda] Could not collect</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @gchanan @kadeng</p>]]></description>
      <pubDate>Wed, 31 Jan 2024 02:18:32 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/118739</guid>
    </item>
    <item>
      <title>inductor stride assertion: make error message more actionable</title>
      <link>https://github.com/pytorch/pytorch/pull/116874</link>
      <description><![CDATA[<p>This assertion has tripped enough times that we know of a few culprits. Some of these culprits are toggleable via config, so I updated the error message to mention that they're worth turning off if you hit the assertion:</p>
<p>(1) layout optimization</p>
<p>(2) ddp optimizer</p>
<p>(3) (technically) this issue, although hopefully it will be fixed soon: https://github.com/pytorch/pytorch/issues/116433</p>
<p>Stack from <a href="https://github.com/ezyang/ghstack">ghstack</a> (oldest at bottom):<br />
* <strong>-&gt;</strong> #116874<br />
* #117587</p>
<p>cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @peterbell10 @ipiszy @yf225 @chenyang78 @kadeng @muchulee8 @aakhundov @ColinPeppler @amjames @desertfire @chauhang</p>]]></description>
      <pubDate>Fri, 05 Jan 2024 09:22:48 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/pull/116874</guid>
    </item>
    <item>
      <title>torch2.1.0 compile+amp+ddp cause NotImplementedError</title>
      <link>https://github.com/pytorch/pytorch/issues/111794</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>When I try to compile the ddp + amp model using torch.compile, I get the following errorÔºö</p>
<p><code>NotImplementedError: argument of type: &lt;class 'torch.amp.autocast_mode.autocast'&gt;</code></p>
<p>Can you help me with this error?</p>
<h3>Error logs</h3>
<p>```<br />
eager train time 0: 2.062772216796875 loss: 12.34566593170166<br />
eager train time 29: 0.12792012786865234 loss: 12.378190040588379<br />
~~~~~~~~~~</p>
<p>[rank0]:[2023-10-20 15:17:41,173] [1/0] torch._dynamo.variables.torch: [WARNING] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored<br />
Traceback (most recent call last):<br />
  File "elastic_ddp.py", line 347, in <module><br />
    demo_basic()<br />
  File "elastic_ddp.py", line 330, in demo_basic<br />
    loss, compile_time = timed(<br />
  File "elastic_ddp.py", line 288, in timed<br />
    result = fn()<br />
  File "elastic_ddp.py", line 331, in <lambda><br />
    lambda: train_opt(ddp_model, inp, opt, grad_scaler))<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn<br />
    return fn(<em>args, </em><em>kwargs)<br />
  File "elastic_ddp.py", line 267, in train<br />
    opt.zero_grad(True)<br />
  File "elastic_ddp.py", line 269, in <resume in train><br />
    predict = model(data[0])<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl<br />
    return self._call_impl(</em>args, <strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl<br />
    return forward_call(*args, </strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward<br />
    else self._run_ddp_forward(<em>inputs, </em><em>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward<br />
    return self.module(</em>inputs, <strong>kwargs)  # type: ignore[index]<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl<br />
    return self._call_impl(*args, </strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl<br />
    return forward_call(<em>args, </em><em>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 487, in catch_errors<br />
    return hijacked_callback(frame, cache_entry, hooks, frame_state)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 641, in _convert_frame<br />
    result = inner_convert(frame, cache_size, hooks, frame_state)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 133, in _fn<br />
    return fn(</em>args, <strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 389, in _convert_frame_assert<br />
    return _compile(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 569, in _compile<br />
    guarded_code = compile_inner(code, one_graph, hooks, transform)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 189, in time_wrapper<br />
    r = func(*args, </strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 491, in compile_inner<br />
    out_code = transform_code_object(code, transform)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py", line 1028, in transform_code_object<br />
    transformations(instructions, code_options)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py", line 458, in transform<br />
    tracer.run()<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2074, in run<br />
    super().run()<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 724, in run<br />
    and self.step()<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 688, in step<br />
    getattr(self, inst.opname)(inst)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py", line 2162, in RETURN_VALUE<br />
    self.output.compile_subgraph(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 833, in compile_subgraph<br />
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)<br />
  File "/opt/conda/lib/python3.8/contextlib.py", line 75, in inner<br />
    return func(<em>args, </em><em>kwds)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 957, in compile_and_call_fx_graph<br />
    compiled_fn = self.call_user_compiler(gm)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 189, in time_wrapper<br />
    r = func(</em>args, <strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/<em>dynamo/output_graph.py", line 1024, in call_user_compiler<br />
    raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/output_graph.py", line 1009, in call_user_compiler<br />
    compiled_fn = compiler_fn(gm, self.example_inputs())<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 436, in compile_fn<br />
    submod_compiler.run(*example_inputs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/interpreter.py", line 138, in run<br />
    self.env[node] = self.run_node(node)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 417, in run_node<br />
    compiled_submod_real = self.compile_submod(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/backends/distributed.py", line 361, in compile_submod<br />
    self.compiler(input_mod, args),<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper<br />
    compiled_gm = compiler_fn(gm, example_inputs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/<strong>init</strong>.py", line 1568, in <strong>call</strong><br />
    return compile_fx(model</em>, inputs_, config_patches=self.config)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 961, in compile_fx<br />
    return compile_fx(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_inductor/compile_fx.py", line 1150, in compile_fx<br />
    return aot_autograd(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn<br />
    cg = aot_module_simplified(gm, example_inputs, </strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 3891, in aot_module_simplified<br />
    compiled_fn = create_aot_dispatcher_function(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/utils.py", line 189, in time_wrapper<br />
    r = func(<em>args, </em><em>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 3429, in create_aot_dispatcher_function<br />
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2212, in aot_wrapper_dedupe<br />
    return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2392, in aot_wrapper_synthetic_base<br />
    return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2804, in aot_dispatch_autograd<br />
    fx_g = aot_dispatch_autograd_graph(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 2781, in aot_dispatch_autograd_graph<br />
    fx_g = create_functionalized_graph(<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py", line 1420, in create_functionalized_graph<br />
    fx_g = make_fx(helper, decomposition_table=aot_config.decompositions)(</em>args)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py", line 809, in wrapped<br />
    t = dispatch_trace(wrap_key(func, args, fx_tracer, pre_dispatch), tracer=fx_tracer, concrete_args=tuple(phs))<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_compile.py", line 24, in inner<br />
    return torch._dynamo.disable(fn, recursive)(<em>args, </em><em>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn<br />
    return fn(</em>args, <strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/external_utils.py", line 17, in inner<br />
    return fn(*args, </strong>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py", line 468, in dispatch_trace<br />
    graph = tracer.trace(root, concrete_args)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn<br />
    return fn(<em>args, </em><em>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/_dynamo/external_utils.py", line 17, in inner<br />
    return fn(</em>args, *<em>kwargs)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py", line 817, in trace<br />
    (self.create_arg(fn(</em>args)),),<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py", line 451, in create_arg<br />
    return super().create_arg(a)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py", line 385, in create_arg<br />
    return super().create_arg(a)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/proxy.py", line 255, in create_arg<br />
    return type(a)(self.create_arg(elem) for elem in a)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/proxy.py", line 255, in <genexpr><br />
    return type(a)(self.create_arg(elem) for elem in a)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py", line 451, in create_arg<br />
    return super().create_arg(a)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py", line 385, in create_arg<br />
    return super().create_arg(a)<br />
  File "/opt/conda/lib/python3.8/site-packages/torch/fx/proxy.py", line 291, in create_arg<br />
    raise NotImplementedError(f"argument of type: {type(a)}")<br />
torch._dynamo.exc.BackendCompilerFailed: backend='compile_fn' raised:<br />
NotImplementedError: argument of type: <class 'torch.amp.autocast_mode.autocast'></p>
<p>While executing %submod_0 : [num_users=3] = call_module<a href="args = (%l_x_,), kwargs = {}">target=submod_0</a><br />
Original traceback:<br />
None</p>
<p>Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information</p>
<p>You can suppress this exception and fall back to eager by setting:<br />
    import torch._dynamo<br />
    torch._dynamo.config.suppress_errors = True</p>
<p>233522-10ea61f2-6f10-11ee-9682-4ee5ea5d12cf-6mprp:6107:6116 [0] NCCL INFO [Service thread] Connection closed by localRank 0<br />
233522-10ea61f2-6f10-11ee-9682-4ee5ea5d12cf-6mprp:6107:6107 [0] NCCL INFO comm 0x55b1609f2ad0 rank 0 nranks 1 cudaDev 0 busId b1000 - Abort COMPLETE</p>
<p>```</p>
<h3>Minified repro</h3>
<p>The code for <code>elastic_ddp.py</code> is shown below.</p>
<p>```python</p>
<h1>coding=utf-8</h1>
<p>import numpy as np<br />
import torch<br />
import torch._dynamo as dynamo<br />
import torch.distributed as dist<br />
import torch.nn as nn<br />
import torch.optim as optim<br />
from torch.nn.parallel import DistributedDataParallel as DDP<br />
from torchvision.models import resnet18, resnet152</p>
<p>using_ckpt = False</p>
<p>def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):<br />
    """3x3 convolution with padding"""<br />
    return nn.Conv2d(in_planes,<br />
                     out_planes,<br />
                     kernel_size=3,<br />
                     stride=stride,<br />
                     padding=dilation,<br />
                     groups=groups,<br />
                     bias=False,<br />
                     dilation=dilation)</p>
<p>def conv1x1(in_planes, out_planes, stride=1):<br />
    """1x1 convolution"""<br />
    return nn.Conv2d(in_planes,<br />
                     out_planes,<br />
                     kernel_size=1,<br />
                     stride=stride,<br />
                     bias=False)</p>
<p>class IBasicBlock(nn.Module):<br />
    expansion = 1</p>
<pre><code>def __init__(self,
             inplanes,
             planes,
             stride=1,
             downsample=None,
             groups=1,
             base_width=64,
             dilation=1):
    super(IBasicBlock, self).__init__()
    if groups != 1 or base_width != 64:
        raise ValueError(
            'BasicBlock only supports groups=1 and base_width=64')
    if dilation &gt; 1:
        raise NotImplementedError(
            "Dilation &gt; 1 not supported in BasicBlock")
    self.bn1 = nn.BatchNorm2d(
        inplanes,
        eps=1e-05,
    )
    self.conv1 = conv3x3(inplanes, planes)
    self.bn2 = nn.BatchNorm2d(
        planes,
        eps=1e-05,
    )
    self.prelu = nn.PReLU(planes)
    self.conv2 = conv3x3(planes, planes, stride)
    self.bn3 = nn.BatchNorm2d(
        planes,
        eps=1e-05,
    )
    self.downsample = downsample
    self.stride = stride

def forward_impl(self, x):
    identity = x
    out = self.bn1(x)
    out = self.conv1(out)
    out = self.bn2(out)
    out = self.prelu(out)
    out = self.conv2(out)
    out = self.bn3(out)
    if self.downsample is not None:
        identity = self.downsample(x)
    out += identity
    return out

def forward(self, x):
    if self.training and using_ckpt:
        return checkpoint(self.forward_impl, x)
    else:
        return self.forward_impl(x)
</code></pre>
<p>class IResNet(nn.Module):<br />
    fc_scale = 7 * 7</p>
<pre><code>def __init__(self,
             block,
             layers,
             dropout=0,
             num_features=512,
             zero_init_residual=False,
             groups=1,
             width_per_group=64,
             replace_stride_with_dilation=None,
             fp16=False):
    super(IResNet, self).__init__()
    self.extra_gflops = 0.0
    self.fp16 = fp16
    self.inplanes = 64
    self.dilation = 1
    if replace_stride_with_dilation is None:
        replace_stride_with_dilation = [False, False, False]
    if len(replace_stride_with_dilation) != 3:
        raise ValueError("replace_stride_with_dilation should be None "
                         "or a 3-element tuple, got {}".format(
                             replace_stride_with_dilation))
    self.groups = groups
    self.base_width = width_per_group
    self.conv1 = nn.Conv2d(3,
                           self.inplanes,
                           kernel_size=3,
                           stride=1,
                           padding=1,
                           bias=False)
    self.bn1 = nn.BatchNorm2d(self.inplanes, eps=1e-05)
    self.prelu = nn.PReLU(self.inplanes)
    self.layer1 = self._make_layer(block, 64, layers[0], stride=2)
    self.layer2 = self._make_layer(block,
                                   128,
                                   layers[1],
                                   stride=2,
                                   dilate=replace_stride_with_dilation[0])
    self.layer3 = self._make_layer(block,
                                   256,
                                   layers[2],
                                   stride=2,
                                   dilate=replace_stride_with_dilation[1])
    self.layer4 = self._make_layer(block,
                                   512,
                                   layers[3],
                                   stride=2,
                                   dilate=replace_stride_with_dilation[2])
    self.bn2 = nn.BatchNorm2d(
        512 * block.expansion,
        eps=1e-05,
    )
    self.dropout = nn.Dropout(p=dropout, inplace=True)
    self.fc = nn.Linear(512 * block.expansion * self.fc_scale, num_features)
    self.features = nn.BatchNorm1d(num_features, eps=1e-05)
    nn.init.constant_(self.features.weight, 1.0)
    self.features.weight.requires_grad = False

    for m in self.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.normal_(m.weight, 0, 0.1)
        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

    if zero_init_residual:
        for m in self.modules():
            if isinstance(m, IBasicBlock):
                nn.init.constant_(m.bn2.weight, 0)

def _make_layer(self, block, planes, blocks, stride=1, dilate=False):
    downsample = None
    previous_dilation = self.dilation
    if dilate:
        self.dilation *= stride
        stride = 1
    if stride != 1 or self.inplanes != planes * block.expansion:
        downsample = nn.Sequential(
            conv1x1(self.inplanes, planes * block.expansion, stride),
            nn.BatchNorm2d(
                planes * block.expansion,
                eps=1e-05,
            ),
        )
    layers = []
    layers.append(
        block(self.inplanes, planes, stride, downsample, self.groups,
              self.base_width, previous_dilation))
    self.inplanes = planes * block.expansion
    for _ in range(1, blocks):
        layers.append(
            block(self.inplanes,
                  planes,
                  groups=self.groups,
                  base_width=self.base_width,
                  dilation=self.dilation))

    return nn.Sequential(*layers)

def forward(self, x):
    with torch.cuda.amp.autocast(True):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.prelu(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.bn2(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
    x = self.fc(x.float())
    x = self.features(x)
    return x
</code></pre>
<p>def _iresnet(arch, block, layers, pretrained, progress, <strong>kwargs):<br />
    model = IResNet(block, layers, </strong>kwargs)<br />
    if pretrained:<br />
        raise ValueError()<br />
    return model</p>
<p>def iresnet18(pretrained=False, progress=True, <strong>kwargs):<br />
    return _iresnet('iresnet18', IBasicBlock, [2, 2, 2, 2], pretrained,<br />
                    progress, </strong>kwargs)</p>
<p>def iresnet34(pretrained=False, progress=True, <strong>kwargs):<br />
    return _iresnet('iresnet34', IBasicBlock, [3, 4, 6, 3], pretrained,<br />
                    progress, </strong>kwargs)</p>
<p>def iresnet50(pretrained=False, progress=True, <strong>kwargs):<br />
    return _iresnet('iresnet50', IBasicBlock, [3, 4, 14, 3], pretrained,<br />
                    progress, </strong>kwargs)</p>
<p>def iresnet100(pretrained=False, progress=True, <strong>kwargs):<br />
    return _iresnet('iresnet100', IBasicBlock, [3, 13, 30, 3], pretrained,<br />
                    progress, </strong>kwargs)</p>
<p>def iresnet200(pretrained=False, progress=True, <strong>kwargs):<br />
    return _iresnet('iresnet200', IBasicBlock, [6, 26, 60, 6], pretrained,<br />
                    progress, </strong>kwargs)</p>
<p>def generate_data(b, device_id=0):<br />
    channel = 3<br />
    height = 112<br />
    width = 112<br />
    return (<br />
        torch.randn(b, channel, height, width).to(torch.float32).cuda(),<br />
        torch.randint(256, (b,)).cuda(device_id),<br />
    )</p>
<p>def init_model(amp=False, device_id=0):<br />
    # return resnet152(num_classes=256).to(torch.float32).cuda(device_id)<br />
    return iresnet200(num_features=256).cuda(device_id)</p>
<p>def train(model, data, opt, grad_scaler):<br />
    opt.zero_grad(True)<br />
    # with torch.autocast(device_type="cuda", enabled=True):<br />
    predict = model(data[0])<br />
    loss = torch.nn.CrossEntropyLoss()(predict, data[1])<br />
    loss = grad_scaler.scale(loss)<br />
    loss.backward()<br />
    opt.step()<br />
    return loss</p>
<p>def eval(model, data):<br />
    with torch.cuda.amp.autocast(enabled=True):<br />
        predict = model(data[0])<br />
        loss = torch.nn.CrossEntropyLoss()(predict, data[1])<br />
    return loss</p>
<p>def timed(fn):<br />
    start = torch.cuda.Event(enable_timing=True)<br />
    end = torch.cuda.Event(enable_timing=True)<br />
    start.record()<br />
    result = fn()<br />
    end.record()<br />
    torch.cuda.synchronize()<br />
    return result, start.elapsed_time(end) / 1000</p>
<p>def demo_basic():<br />
    N_ITERS = 30<br />
    dist.init_process_group("nccl")<br />
    rank = dist.get_rank()<br />
    print(f"Start running basic DDP example on rank {rank}.")</p>
<pre><code># create model and move it to GPU with id rank
device_id = rank % torch.cuda.device_count()
# model = ToyModel().to(device_id)
dynamo.reset()
model = init_model(device_id=device_id)
ddp_model = DDP(model, device_ids=[device_id])

opt = optim.SGD(ddp_model.parameters(), lr=0.001)
# data = generate_data(16, device_id=device_id)
grad_scaler = torch.cuda.amp.GradScaler(init_scale=2.0)
eager_times = []
for i in range(N_ITERS):
    inp = generate_data(16)
    loss, eager_time = timed(
        lambda: train(ddp_model, inp, opt, grad_scaler))
    eager_times.append(eager_time)
    print(f"eager train time {i}: {eager_time}", "loss:", loss.item())
print("~" * 10)
dynamo.reset()
model = init_model(device_id=device_id)
ddp_model = DDP(model, device_ids=[device_id])
opt = optim.SGD(ddp_model.parameters(), lr=0.001)
grad_scaler = torch.cuda.amp.GradScaler(init_scale=2.0)
train_opt = torch.compile(train,
                          options={"triton.cudagraphs": True},
                          backend="inductor")

compile_times = []
for i in range(N_ITERS):
    inp = generate_data(16)
    loss, compile_time = timed(
        lambda: train_opt(ddp_model, inp, opt, grad_scaler))
    compile_times.append(compile_time)
    print(f"compile train time {i}: {compile_time}", "loss:", loss.item())
print("~" * 10)

eager_med = np.median(eager_times)
compile_med = np.median(compile_times)
speedup = eager_med / compile_med
print(
    f"(train) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x"
)
print("~" * 10)
dist.destroy_process_group()
</code></pre>
<p>if <strong>name</strong> == "<strong>main</strong>":<br />
    demo_basic()</p>
<p>```</p>
<p>The running commands are as follows:</p>
<p><code>shell
torchrun --nnodes=1 --nproc_per_node=1 --node_rank=0 --master_addr=127.0.0.1 elastic_ddp.py</code></p>
<h3>Versions</h3>
<p>```<br />
Collecting environment information...<br />
PyTorch version: 2.1.0+cu118<br />
Is debug build: False<br />
CUDA used to build PyTorch: 11.8<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 20.04.2 LTS (x86_64)<br />
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0<br />
Clang version: Could not collect<br />
CMake version: version 3.22.1<br />
Libc version: glibc-2.31</p>
<p>Python version: 3.8.12 (default, Oct 12 2021, 13:49:34)  [GCC 7.5.0] (64-bit runtime)<br />
Python platform: Linux-3.10.0-1062.el7.x86_64-x86_64-with-glibc2.17<br />
Is CUDA available: True<br />
CUDA runtime version: 11.6.124<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: Tesla V100-SXM2-32GB<br />
Nvidia driver version: 510.47.03<br />
cuDNN version: Probably one of the following:<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn.so.8.4.0<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.4.0<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.4.0<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.4.0<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.4.0<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.4.0<br />
/usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.4.0<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:        x86_64<br />
CPU op-mode(s):      32-bit, 64-bit<br />
Byte Order:          Little Endian<br />
Address sizes:       46 bits physical, 48 bits virtual<br />
CPU(s):              96<br />
On-line CPU(s) list: 0-95<br />
Thread(s) per core:  2<br />
Core(s) per socket:  24<br />
Socket(s):           2<br />
NUMA node(s):        2<br />
Vendor ID:           GenuineIntel<br />
CPU family:          6<br />
Model:               85<br />
Model name:          Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz<br />
Stepping:            7<br />
CPU MHz:             3170.947<br />
CPU max MHz:         4000.0000<br />
CPU min MHz:         1000.0000<br />
BogoMIPS:            4800.00<br />
Virtualization:      VT-x<br />
L1d cache:           1.5 MiB<br />
L1i cache:           1.5 MiB<br />
L2 cache:            48 MiB<br />
L3 cache:            71.5 MiB<br />
NUMA node0 CPU(s):   0-23,48-71<br />
NUMA node1 CPU(s):   24-47,72-95<br />
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_ppin intel_pt ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear spec_ctrl intel_stibp flush_l1d arch_capabilities</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.22.4<br />
[pip3] torch==2.1.0+cu118<br />
[pip3] torchaudio==2.1.0+cu118<br />
[pip3] torchdata==0.7.0<br />
[pip3] torchtext==0.16.0+cpu<br />
[pip3] torchvision==0.16.0+cu118<br />
[pip3] triton==2.1.0<br />
[conda] numpy                     1.22.4                   pypi_0    pypi<br />
[conda] torch                     2.1.0+cu118              pypi_0    pypi<br />
[conda] torchaudio                2.1.0+cu118              pypi_0    pypi<br />
[conda] torchdata                 0.7.0                    pypi_0    pypi<br />
[conda] torchtext                 0.16.0+cpu               pypi_0    pypi<br />
[conda] torchvision               0.16.0+cu118             pypi_0    pypi<br />
[conda] triton                    2.1.0                    pypi_0    pypi<br />
```</p>
<p>cc @mrshenli @pritamdamania87 @zhaojuanmao @satgera @rohan-varma @gqchen @aazzolini @osalpekar @jiayisuse @H-Huang @kwen2501 @awgu @penguinwu @fegin @XilunWu @wanchaol @fduwjj @wz337 @tianyu-l @wconstab @yf225 @chauhang @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @voznesenskym @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @chenyang78 @kadeng @aakhundov @mcarilli @ptrblck @leslie-fang-intel</p>]]></description>
      <pubDate>Mon, 23 Oct 2023 02:52:58 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/111794</guid>
    </item>
    <item>
      <title>AOTAutograd based torch.compile doesn't capture manual seed setting in the graph</title>
      <link>https://github.com/pytorch/pytorch/issues/95161</link>
      <description><![CDATA[<h3>üêõ Describe the bug</h3>
<p>The following code breaks with AOTautograd based 2.0 torch.compile -<br />
```<br />
from typing import List<br />
import torch<br />
import torch._dynamo as dynamo<br />
from torch._functorch.aot_autograd import aot_module_simplified</p>
<p>dynamo.reset()</p>
<p>def my_non_aot_compiler(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):<br />
    print(gm.code)<br />
    return gm.forward</p>
<p>def my_aot_compiler(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):<br />
    def my_compiler(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):<br />
        print(gm.code)<br />
        return gm.forward</p>
<pre><code># Invoke AOTAutograd
return aot_module_simplified(
    gm,
    example_inputs,
    fw_compiler=my_compiler
)
</code></pre>
<p>def my_example():<br />
    torch.manual_seed(0)<br />
    d_float32 = torch.rand((8, 8), device="cpu")<br />
    return d_float32 + d_float32</p>
<p>compiled_fn = torch.compile(backend=my_aot_compiler)(my_example)</p>
<h1>compiled_fn = torch.compile(backend=my_non_aot_compiler)(my_example)</h1>
<p>r1 = compiled_fn()<br />
r2 = compiled_fn()<br />
print("Results match? ", torch.allclose(r1, r2, atol = 0.001, rtol = 0.001))<br />
<code>When</code>my_aot_compiler<code>is used, the result is wrong as the graph doesn't capture torch.manual_seed -</code><br />
def forward(self):<br />
    rand = torch.ops.aten.rand.default([8, 8], device = device(type='cpu'), pin_memory = False)<br />
    add = torch.ops.aten.add.Tensor(rand, rand);  rand = None<br />
    return (add,)</p>
<p>Results match?  False<br />
/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py:1251: UserWarning: Your compiler for AOTAutograd is returning a a function that doesn't take boxed arguments. Please wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. See https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.<br />
  warnings.warn(<br />
```</p>
<p>However, when a non-AOT autograd based compiler <code>my_non_aot_compiler</code> is used, torch.manual_seed is captured in the graph and the result is correct -<br />
```<br />
def forward(self):<br />
    manual_seed = torch.random.manual_seed(0)<br />
    rand = torch.rand((8, 8), device = 'cpu')<br />
    add = rand + rand;  rand = None<br />
    return (add,)</p>
<p>Results match?  True<br />
```</p>
<h3>Versions</h3>
<p>PyTorch version: 2.0.0.dev20230220+cu117<br />
Is debug build: False<br />
CUDA used to build PyTorch: 11.7<br />
ROCM used to build PyTorch: N/A</p>
<p>OS: Ubuntu 20.04.5 LTS (x86_64)<br />
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0<br />
Clang version: 10.0.0-4ubuntu1 <br />
CMake version: version 3.25.2<br />
Libc version: glibc-2.31</p>
<p>Python version: 3.8.10 (default, Nov 14 2022, 12:59:47)  [GCC 9.4.0] (64-bit runtime)<br />
Python platform: Linux-5.10.147+-x86_64-with-glibc2.29<br />
Is CUDA available: True<br />
CUDA runtime version: 11.6.124<br />
CUDA_MODULE_LOADING set to: LAZY<br />
GPU models and configuration: GPU 0: Tesla T4<br />
Nvidia driver version: 510.47.03<br />
cuDNN version: Probably one of the following:<br />
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.4.0<br />
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.4.0<br />
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.4.0<br />
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.4.0<br />
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.4.0<br />
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.4.0<br />
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.4.0<br />
HIP runtime version: N/A<br />
MIOpen runtime version: N/A<br />
Is XNNPACK available: True</p>
<p>CPU:<br />
Architecture:                    x86_64<br />
CPU op-mode(s):                  32-bit, 64-bit<br />
Byte Order:                      Little Endian<br />
Address sizes:                   46 bits physical, 48 bits virtual<br />
CPU(s):                          2<br />
On-line CPU(s) list:             0,1<br />
Thread(s) per core:              2<br />
Core(s) per socket:              1<br />
Socket(s):                       1<br />
NUMA node(s):                    1<br />
Vendor ID:                       GenuineIntel<br />
CPU family:                      6<br />
Model:                           85<br />
Model name:                      Intel(R) Xeon(R) CPU @ 2.00GHz<br />
Stepping:                        3<br />
CPU MHz:                         2000.140<br />
BogoMIPS:                        4000.28<br />
Hypervisor vendor:               KVM<br />
Virtualization type:             full<br />
L1d cache:                       32 KiB<br />
L1i cache:                       32 KiB<br />
L2 cache:                        1 MiB<br />
L3 cache:                        38.5 MiB<br />
NUMA node0 CPU(s):               0,1<br />
Vulnerability Itlb multihit:     Not affected<br />
Vulnerability L1tf:              Mitigation; PTE Inversion<br />
Vulnerability Mds:               Vulnerable; SMT Host state unknown<br />
Vulnerability Meltdown:          Vulnerable<br />
Vulnerability Mmio stale data:   Vulnerable<br />
Vulnerability Retbleed:          Vulnerable<br />
Vulnerability Spec store bypass: Vulnerable<br />
Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers<br />
Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected<br />
Vulnerability Srbds:             Not affected<br />
Vulnerability Tsx async abort:   Vulnerable<br />
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities</p>
<p>Versions of relevant libraries:<br />
[pip3] numpy==1.24.2<br />
[pip3] pytorch-triton==2.0.0+c8bfe3f548<br />
[pip3] torch==2.0.0.dev20230220+cu117<br />
[pip3] torchaudio==0.13.1+cu116<br />
[pip3] torchsummary==1.5.1<br />
[pip3] torchtext==0.14.1<br />
[pip3] torchvision==0.14.1+cu116<br />
[conda] Could not collect</p>
<p>cc @ezyang @msaroufim @bdhirsh @anijain2305 @zou3519 @chauhang @wconstab @soumith @ngimel @voznesenskym @yanboliang @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @desertfire</p>]]></description>
      <pubDate>Mon, 20 Feb 2023 04:15:09 GMT</pubDate>
      <guid isPermaLink="true">https://github.com/pytorch/pytorch/issues/95161</guid>
    </item>
  </channel>
</rss>
